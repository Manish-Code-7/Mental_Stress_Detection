{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247940c9-4671-402b-96af-ddcda4d89080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 17:30:27,905 | INFO | üöÄ Loading dataset for stress detection...\n",
      "2025-11-07 17:30:27,932 | INFO | ‚úÖ Loaded dataset successfully using encoding: utf-8\n",
      "2025-11-07 17:30:27,933 | INFO | üìä Dataset Shape: (2838, 116)\n",
      "2025-11-07 17:30:27,933 | INFO | üìë Columns: ['subreddit', 'post_id', 'sentence_range', 'text', 'id', 'label', 'confidence', 'social_timestamp', 'social_karma', 'syntax_ari', 'lex_liwc_WC', 'lex_liwc_Analytic', 'lex_liwc_Clout', 'lex_liwc_Authentic', 'lex_liwc_Tone', 'lex_liwc_WPS', 'lex_liwc_Sixltr', 'lex_liwc_Dic', 'lex_liwc_function', 'lex_liwc_pronoun', 'lex_liwc_ppron', 'lex_liwc_i', 'lex_liwc_we', 'lex_liwc_you', 'lex_liwc_shehe', 'lex_liwc_they', 'lex_liwc_ipron', 'lex_liwc_article', 'lex_liwc_prep', 'lex_liwc_auxverb', 'lex_liwc_adverb', 'lex_liwc_conj', 'lex_liwc_negate', 'lex_liwc_verb', 'lex_liwc_adj', 'lex_liwc_compare', 'lex_liwc_interrog', 'lex_liwc_number', 'lex_liwc_quant', 'lex_liwc_affect', 'lex_liwc_posemo', 'lex_liwc_negemo', 'lex_liwc_anx', 'lex_liwc_anger', 'lex_liwc_sad', 'lex_liwc_social', 'lex_liwc_family', 'lex_liwc_friend', 'lex_liwc_female', 'lex_liwc_male', 'lex_liwc_cogproc', 'lex_liwc_insight', 'lex_liwc_cause', 'lex_liwc_discrep', 'lex_liwc_tentat', 'lex_liwc_certain', 'lex_liwc_differ', 'lex_liwc_percept', 'lex_liwc_see', 'lex_liwc_hear', 'lex_liwc_feel', 'lex_liwc_bio', 'lex_liwc_body', 'lex_liwc_health', 'lex_liwc_sexual', 'lex_liwc_ingest', 'lex_liwc_drives', 'lex_liwc_affiliation', 'lex_liwc_achieve', 'lex_liwc_power', 'lex_liwc_reward', 'lex_liwc_risk', 'lex_liwc_focuspast', 'lex_liwc_focuspresent', 'lex_liwc_focusfuture', 'lex_liwc_relativ', 'lex_liwc_motion', 'lex_liwc_space', 'lex_liwc_time', 'lex_liwc_work', 'lex_liwc_leisure', 'lex_liwc_home', 'lex_liwc_money', 'lex_liwc_relig', 'lex_liwc_death', 'lex_liwc_informal', 'lex_liwc_swear', 'lex_liwc_netspeak', 'lex_liwc_assent', 'lex_liwc_nonflu', 'lex_liwc_filler', 'lex_liwc_AllPunc', 'lex_liwc_Period', 'lex_liwc_Comma', 'lex_liwc_Colon', 'lex_liwc_SemiC', 'lex_liwc_QMark', 'lex_liwc_Exclam', 'lex_liwc_Dash', 'lex_liwc_Quote', 'lex_liwc_Apostro', 'lex_liwc_Parenth', 'lex_liwc_OtherP', 'lex_dal_max_pleasantness', 'lex_dal_max_activation', 'lex_dal_max_imagery', 'lex_dal_min_pleasantness', 'lex_dal_min_activation', 'lex_dal_min_imagery', 'lex_dal_avg_activation', 'lex_dal_avg_imagery', 'lex_dal_avg_pleasantness', 'social_upvote_ratio', 'social_num_comments', 'syntax_fk_grade', 'sentiment']\n",
      "2025-11-07 17:30:27,947 | INFO | üîç Missing Values: 0 | Duplicates: 0\n",
      "2025-11-07 17:30:27,987 | INFO | üìÅ Dataset profile saved at: preprocessors/dataset_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " MENTAL STRESS DETECTION - DATA SUMMARY \n",
      "============================================================\n",
      "Shape: (2838, 116)\n",
      "Possible Label Column: subreddit\n",
      "Text Columns: ['post_id', 'sentence_range', 'text']\n",
      "Duplicate Rows: 0\n",
      "Missing Values: 0\n",
      "\n",
      "‚úÖ Dataset successfully loaded and validated. Ready for preprocessing.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üì¶ STANDARDIZED SETUP - MENTAL STRESS DETECTION PROJECT\n",
    "# ==========================================\n",
    "\n",
    "# --- Core Imports ---\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Visualization (optional for EDA) ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# --- Text & NLP Utilities ---\n",
    "import re\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "# --- Machine Learning ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- System Utilities ---\n",
    "import joblib\n",
    "from typing import Dict, Any\n",
    "\n",
    "# --- Warnings ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================\n",
    "# üöÄ LOGGING CONFIGURATION\n",
    "# ==========================================\n",
    "LOG_DIR = Path(\"logs\")\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "log_file = LOG_DIR / \"stress_detection.log\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[\n",
    "        RotatingFileHandler(log_file, maxBytes=1_000_000, backupCount=3),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ==========================================\n",
    "# üóÇÔ∏è DIRECTORY STRUCTURE (MODELS / REPORTS / FRONTEND)\n",
    "# ==========================================\n",
    "for folder in [\"models\", \"preprocessors\", \"reports\", \"artifacts\"]:\n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "\n",
    "# ==========================================\n",
    "# üß† DATA LOADING FUNCTION\n",
    "# ==========================================\n",
    "def load_dataset(file_path: str, encoding: str = \"utf-8\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load dataset with multiple fallback encodings and detailed validation.\n",
    "    Returns: pandas DataFrame\n",
    "    \"\"\"\n",
    "    encodings = [encoding, \"utf-8\", \"latin-1\", \"cp1252\"]\n",
    "    dataset = None\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            dataset = pd.read_csv(file_path, encoding=enc, on_bad_lines=\"skip\", low_memory=False)\n",
    "            logger.info(f\"‚úÖ Loaded dataset successfully using encoding: {enc}\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    if dataset is None:\n",
    "        raise ValueError(f\"‚ùå Failed to load dataset using all encodings: {encodings}\")\n",
    "    \n",
    "    logger.info(f\"üìä Dataset Shape: {dataset.shape}\")\n",
    "    logger.info(f\"üìë Columns: {list(dataset.columns)}\")\n",
    "    logger.info(f\"üîç Missing Values: {dataset.isnull().sum().sum()} | Duplicates: {dataset.duplicated().sum()}\")\n",
    "    return dataset\n",
    "\n",
    "# ==========================================\n",
    "# üîé VALIDATION FUNCTION\n",
    "# ==========================================\n",
    "def validate_stress_dataset(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate dataset structure for stress detection tasks.\n",
    "    Identifies potential text and label columns, missing data, duplicates, etc.\n",
    "    \"\"\"\n",
    "    validation = {\n",
    "        \"total_samples\": len(df),\n",
    "        \"missing_values\": df.isnull().sum().to_dict(),\n",
    "        \"duplicate_rows\": int(df.duplicated().sum()),\n",
    "        \"text_columns\": [],\n",
    "        \"label_column\": None,\n",
    "        \"issues\": []\n",
    "    }\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            avg_len = df[col].dropna().astype(str).str.len().mean()\n",
    "            unique_vals = df[col].nunique(dropna=True)\n",
    "\n",
    "            if avg_len > 15 or unique_vals > 30:\n",
    "                validation[\"text_columns\"].append(col)\n",
    "            elif unique_vals <= 10:\n",
    "                validation[\"label_column\"] = col\n",
    "\n",
    "    for text_col in validation[\"text_columns\"]:\n",
    "        short_count = df[text_col].astype(str).str.len().lt(5).sum()\n",
    "        if short_count > 0:\n",
    "            validation[\"issues\"].append(f\"Column '{text_col}' has {short_count} very short entries\")\n",
    "\n",
    "    return validation\n",
    "\n",
    "# ==========================================\n",
    "# üíæ SAVE DATASET PROFILE\n",
    "# ==========================================\n",
    "def save_dataset_profile(df: pd.DataFrame, validation: Dict[str, Any]):\n",
    "    profile = {\n",
    "        \"dataset_info\": {\n",
    "            \"shape\": df.shape,\n",
    "            \"columns\": list(df.columns),\n",
    "            \"text_columns\": validation[\"text_columns\"],\n",
    "            \"label_column\": validation[\"label_column\"],\n",
    "            \"duplicates\": validation[\"duplicate_rows\"],\n",
    "            \"missing\": sum(validation[\"missing_values\"].values())\n",
    "        },\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    config_path = Path(\"preprocessors/dataset_config.json\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(profile, f, indent=2)\n",
    "    logger.info(f\"üìÅ Dataset profile saved at: {config_path}\")\n",
    "    return profile\n",
    "\n",
    "# ==========================================\n",
    "# ‚öôÔ∏è EXECUTION - LOAD AND VALIDATE\n",
    "# ==========================================\n",
    "logger.info(\"üöÄ Loading dataset for stress detection...\")\n",
    "DATA_PATH = \"stress.csv\"   # modify if needed\n",
    "try:\n",
    "    df_raw = load_dataset(DATA_PATH)\n",
    "    df = df_raw.copy()\n",
    "    validation = validate_stress_dataset(df)\n",
    "    profile = save_dataset_profile(df, validation)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\" MENTAL STRESS DETECTION - DATA SUMMARY \")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Possible Label Column: {validation['label_column']}\")\n",
    "    print(f\"Text Columns: {validation['text_columns']}\")\n",
    "    print(f\"Duplicate Rows: {validation['duplicate_rows']}\")\n",
    "    print(f\"Missing Values: {sum(validation['missing_values'].values())}\")\n",
    "    if validation['issues']:\n",
    "        print(\"\\n‚ö†Ô∏è Issues Found:\")\n",
    "        for issue in validation['issues']:\n",
    "            print(f\"  - {issue}\")\n",
    "    print(\"\\n‚úÖ Dataset successfully loaded and validated. Ready for preprocessing.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Data loading failed: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1aab86-ebfd-4807-994f-8b6d779616dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 17:30:32,195 | INFO | Text column stats computed: ['post_id', 'sentence_range', 'text']\n",
      "2025-11-07 17:30:32,214 | INFO | Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-11-07 17:30:32,219 | INFO | Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-11-07 17:30:32,320 | INFO | Saved figure: reports/figures/label_distribution.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ 'stress.csv' loaded successfully as 'stress'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 17:30:32,462 | INFO | Saved figure: reports/figures/subreddit_distribution.png\n",
      "2025-11-07 17:30:32,574 | INFO | Saved figure: reports/figures/subreddit_vs_label.png\n",
      "2025-11-07 17:30:32,971 | INFO | Saved figure: reports/figures/post_id_wordcloud_overall.png\n",
      "2025-11-07 17:30:33,316 | INFO | Saved figure: reports/figures/post_id_wordcloud_1.png\n",
      "2025-11-07 17:30:33,845 | INFO | Saved figure: reports/figures/text_wordcloud_overall.png\n",
      "2025-11-07 17:30:34,518 | INFO | Saved figure: reports/figures/text_wordcloud_1.png\n",
      "2025-11-07 17:30:34,520 | INFO | EDA report saved to reports/eda_results.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ EDA COMPLETE\n",
      "üìä Results saved: reports/eda_results.json\n",
      "üñºÔ∏è Figures saved: reports/figures/\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üåø STANDARDIZED EDA - Mental Stress Detection\n",
    "# ===============================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # Allows saving plots on headless servers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ===============================\n",
    "# Setup\n",
    "# ===============================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Logging\n",
    "logger = logging.getLogger(__name__)\n",
    "if not logger.handlers:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "# Output directories\n",
    "REPORT_DIR = Path(\"reports\")\n",
    "FIG_DIR = REPORT_DIR / \"figures\"\n",
    "REPORT_DIR.mkdir(exist_ok=True)\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Ensure NLTK stopwords are available\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\", quiet=True)\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "EN_STOPWORDS = set(stopwords.words(\"english\"))\n",
    "MENTAL_STOPWORDS = EN_STOPWORDS.union({\n",
    "    'like','get','would','could','should','really','much','even','also','still',\n",
    "    'think','feel','know','going','want','need','one','way','people','time',\n",
    "    'good','bad','well','right','thing'\n",
    "})\n",
    "\n",
    "SAVE_FIGURES = True\n",
    "TEXT_COL_BLACKLIST = {\"label\", \"subreddit\"}\n",
    "\n",
    "# ===============================\n",
    "# Utility Functions\n",
    "# ===============================\n",
    "def dataset_summary(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"Return overall dataset summary.\"\"\"\n",
    "    mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    return {\n",
    "        \"shape\": df.shape,\n",
    "        \"memory_mb\": round(mem, 2),\n",
    "        \"missing_values\": df.isnull().sum().to_dict(),\n",
    "        \"duplicates\": int(df.duplicated().sum()),\n",
    "        \"numeric_cols\": df.select_dtypes(include=[np.number]).columns.tolist(),\n",
    "        \"object_cols\": df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    }\n",
    "\n",
    "def text_column_stats(df: pd.DataFrame, text_cols: List[str]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Compute vectorized text statistics.\"\"\"\n",
    "    stats = {}\n",
    "    for col in text_cols:\n",
    "        s = df[col].astype(str).fillna(\"\")\n",
    "        lens = s.str.len()\n",
    "        words = s.str.split().str.len().fillna(0).astype(int)\n",
    "        stats[col] = {\n",
    "            \"avg_length\": float(lens.mean()),\n",
    "            \"avg_word_count\": float(words.mean()),\n",
    "            \"max_length\": int(lens.max()),\n",
    "            \"min_length\": int(lens.min()),\n",
    "            \"short_texts\": int((lens < 50).sum()),\n",
    "            \"long_texts\": int((lens > 1000).sum()),\n",
    "            \"unique_values\": int(df[col].nunique())\n",
    "        }\n",
    "    logger.info(f\"Text column stats computed: {list(stats.keys())}\")\n",
    "    return stats\n",
    "\n",
    "def class_distribution(df: pd.DataFrame, label_col: str) -> Dict[str, Any]:\n",
    "    \"\"\"Return class distribution and imbalance ratio.\"\"\"\n",
    "    if label_col not in df.columns:\n",
    "        return {}\n",
    "    counts = df[label_col].value_counts()\n",
    "    ratio = None\n",
    "    if len(counts) == 2 and counts.min() > 0:\n",
    "        ratio = round(float(counts.max() / counts.min()), 2)\n",
    "    return {\n",
    "        \"counts\": counts.to_dict(),\n",
    "        \"proportions\": (counts / counts.sum()).round(4).to_dict(),\n",
    "        \"imbalance_ratio\": ratio\n",
    "    }\n",
    "\n",
    "def save_or_show(fig, name: str):\n",
    "    \"\"\"Save figure to reports/figures.\"\"\"\n",
    "    if SAVE_FIGURES:\n",
    "        path = FIG_DIR / f\"{name}.png\"\n",
    "        fig.savefig(path, bbox_inches=\"tight\", dpi=150)\n",
    "        plt.close(fig)\n",
    "        logger.info(f\"Saved figure: {path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# ===============================\n",
    "# Visualization Functions\n",
    "# ===============================\n",
    "def plot_distribution(df, col):\n",
    "    if col not in df.columns:\n",
    "        return\n",
    "    counts = df[col].value_counts()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    sns.barplot(x=counts.index, y=counts.values, ax=axes[0])\n",
    "    axes[0].set_title(f\"{col.capitalize()} Distribution\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "    axes[1].pie(counts.values, labels=counts.index, autopct=\"%.1f%%\", startangle=140)\n",
    "    axes[1].set_title(f\"{col.capitalize()} Percentage\")\n",
    "    save_or_show(fig, f\"{col}_distribution\")\n",
    "\n",
    "def subreddit_vs_label(df, subreddit_col=\"subreddit\", label_col=\"label\"):\n",
    "    if subreddit_col not in df.columns or label_col not in df.columns:\n",
    "        return\n",
    "    top_subs = df[subreddit_col].value_counts().head(10).index.tolist()\n",
    "    sub_df = df[df[subreddit_col].isin(top_subs)]\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    sns.countplot(data=sub_df, x=subreddit_col, hue=label_col, ax=ax, order=top_subs)\n",
    "    ax.set_title(\"Subreddit vs Stress Level\")\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    save_or_show(fig, \"subreddit_vs_label\")\n",
    "\n",
    "def generate_wordcloud(df, text_col, label_col=None):\n",
    "    \"\"\"Generate per-label and overall word clouds.\"\"\"\n",
    "    def clean_text(t):\n",
    "        t = str(t).lower()\n",
    "        t = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+\", \"\", t)\n",
    "        t = re.sub(r\"[^a-z\\s]\", \" \", t)\n",
    "        return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    \n",
    "    if text_col not in df.columns:\n",
    "        return\n",
    "    \n",
    "    labels = [None]\n",
    "    if label_col and label_col in df.columns:\n",
    "        labels = sorted(df[label_col].dropna().unique(), key=lambda x: str(x))\n",
    "    \n",
    "    for label in labels:\n",
    "        subset = df if label is None else df[df[label_col] == label]\n",
    "        text = \" \".join(clean_text(t) for t in subset[text_col].dropna().astype(str))\n",
    "        if not text.strip():\n",
    "            continue\n",
    "        wc = WordCloud(width=900, height=450, stopwords=MENTAL_STOPWORDS,\n",
    "                       background_color=\"white\", max_words=150, random_state=42).generate(text)\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.imshow(wc, interpolation=\"bilinear\")\n",
    "        title = \"Overall Word Cloud\" if label is None else f\"Word Cloud - {label}\"\n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.axis(\"off\")\n",
    "        fname = f\"{text_col}_wordcloud_{label if label else 'overall'}\"\n",
    "        save_or_show(fig, fname)\n",
    "\n",
    "# ===============================\n",
    "# Main EDA Runner\n",
    "# ===============================\n",
    "def run_eda(df: pd.DataFrame, label_col=\"label\", subreddit_col=\"subreddit\") -> Dict[str, Any]:\n",
    "    \"\"\"Perform complete EDA and save results.\"\"\"\n",
    "    report = {}\n",
    "    report[\"summary\"] = dataset_summary(df)\n",
    "    text_cols = [c for c in df.select_dtypes(include=[\"object\", \"category\"]).columns if c not in TEXT_COL_BLACKLIST]\n",
    "    report[\"text_stats\"] = text_column_stats(df, text_cols)\n",
    "    report[\"class_distribution\"] = class_distribution(df, label_col)\n",
    "    \n",
    "    # Visualizations\n",
    "    for col in [label_col, subreddit_col]:\n",
    "        if col in df.columns:\n",
    "            plot_distribution(df, col)\n",
    "    if subreddit_col in df.columns and label_col in df.columns:\n",
    "        subreddit_vs_label(df, subreddit_col, label_col)\n",
    "    for text_col in text_cols:\n",
    "        generate_wordcloud(df, text_col, label_col)\n",
    "    \n",
    "    # Save JSON\n",
    "    with open(REPORT_DIR / \"eda_results.json\", \"w\") as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    logger.info(\"EDA report saved to reports/eda_results.json\")\n",
    "    return report\n",
    "\n",
    "# ===============================\n",
    "# ‚úÖ SAFE EXECUTION BLOCK\n",
    "# ===============================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    stress\n",
    "except NameError:\n",
    "    if Path(\"stress.csv\").exists():\n",
    "        stress = pd.read_csv(\"stress.csv\")\n",
    "        print(\"üìÑ 'stress.csv' loaded successfully as 'stress'\")\n",
    "    elif Path(\"data.csv\").exists():\n",
    "        stress = pd.read_csv(\"data.csv\")\n",
    "        print(\"üìÑ 'data.csv' loaded successfully as 'stress'\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"‚ùå No dataset found. Run the data loading cell first.\")\n",
    "\n",
    "try:\n",
    "    eda_report = run_eda(stress, label_col=\"label\", subreddit_col=\"subreddit\")\n",
    "    print(\"\\n‚úÖ EDA COMPLETE\")\n",
    "    print(\"üìä Results saved: reports/eda_results.json\")\n",
    "    print(\"üñºÔ∏è Figures saved: reports/figures/\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"‚ùå EDA FAILED:\", str(e))\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0bed8-0dd5-45a6-b6ce-ef8e51536bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENHANCED TEXT PREPROCESSING FOR MENTAL STRESS DETECTION\n",
      "============================================================\n",
      "üìò Text column detected: 'post_id'\n",
      "\n",
      "üìÑ Sample Original Texts:\n",
      "1. 8601tu...\n",
      "2. 8lbrx9...\n",
      "3. 9ch1zh...\n",
      "üßπ Cleaning 2,838 texts in 3 batches of 1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 30044.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 44157.54it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 838/838 [00:00<00:00, 40760.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed in 0.1s\n",
      "\n",
      "üßæ Sample Cleaned Texts:\n",
      "1. Original: 8601tu...\n",
      "   Cleaned:  tu...\n",
      "2. Original: 8lbrx9...\n",
      "   Cleaned:  lbrx...\n",
      "3. Original: 9ch1zh...\n",
      "   Cleaned:  ch zh...\n",
      "\n",
      "üßÆ CLEANING STATISTICS:\n",
      "Average Original Length: 6.0 chars\n",
      "Average Cleaned Length:  4.3 chars\n",
      "Length Reduction:        27.6%\n",
      "Average Original Words:  1.0\n",
      "Average Cleaned Words:   1.1\n",
      "Word Reduction:          -8.4%\n",
      "‚ö†Ô∏è 336 rows resulted in empty text after cleaning.\n",
      "\n",
      "üìÅ Configuration saved ‚Üí preprocessors/text_preprocessing_config.json\n",
      "\n",
      "‚úÖ Text preprocessing complete! New column 'clean_text' created.\n",
      "Final dataset shape: (2838, 117)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üß† ENHANCED NLP PREPROCESSING - MENTAL STRESS DETECTION\n",
    "# ==========================================\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import string\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================\n",
    "# SETUP\n",
    "# ==========================================\n",
    "tqdm.pandas()\n",
    "Path(\"preprocessors\").mkdir(exist_ok=True)\n",
    "\n",
    "# --- Load required NLTK resources ---\n",
    "required_nltk_downloads = [\"stopwords\", \"wordnet\", \"punkt\", \"omw-1.4\"]\n",
    "for r in required_nltk_downloads:\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{r}\")\n",
    "    except LookupError:\n",
    "        nltk.download(r, quiet=True)\n",
    "\n",
    "# --- Initialize spaCy (if available) ---\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"tok2vec\", \"tagger\", \"attribute_ruler\"])\n",
    "    LEMMATIZER = \"spacy\"\n",
    "except OSError:\n",
    "    print(\"‚ö†Ô∏è spaCy model not found. Falling back to NLTK lemmatizer.\")\n",
    "    nlp = None\n",
    "    LEMMATIZER = \"nltk\"\n",
    "\n",
    "# --- Stopwords setup ---\n",
    "MENTAL_STOPWORDS = set(stopwords.words(\"english\")).union({\n",
    "    \"like\", \"get\", \"would\", \"could\", \"should\", \"really\", \"much\", \"even\", \"also\", \"still\",\n",
    "    \"think\", \"feel\", \"know\", \"going\", \"want\", \"need\", \"one\", \"way\", \"people\", \"time\",\n",
    "    \"good\", \"bad\", \"well\", \"right\", \"thing\", \"reddit\", \"post\", \"comment\", \"subreddit\", \"thread\",\n",
    "    \"op\", \"edit\", \"update\", \"really\", \"pretty\", \"quite\", \"very\", \"super\", \"totally\", \"completely\",\n",
    "    \"absolutely\", \"definitely\", \"probably\", \"maybe\", \"perhaps\", \"might\"\n",
    "})\n",
    "\n",
    "PRESERVE_KEYWORDS = {\n",
    "    \"stress\", \"stressed\", \"anxiety\", \"anxious\", \"depression\", \"depressed\", \"panic\", \"worry\",\n",
    "    \"fear\", \"overwhelmed\", \"tired\", \"exhausted\", \"sad\", \"happy\", \"angry\", \"frustrated\",\n",
    "    \"hopeless\", \"helpless\", \"therapy\", \"counseling\", \"medication\", \"sleep\", \"insomnia\",\n",
    "    \"work\", \"job\", \"family\", \"relationship\", \"health\", \"money\", \"support\", \"help\",\n",
    "    \"better\", \"worse\", \"difficult\", \"hard\", \"easy\"\n",
    "}\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# ==========================================\n",
    "# CLEANING HELPERS\n",
    "# ==========================================\n",
    "def clean_social_text(text: str) -> str:\n",
    "    \"\"\"Remove social media noise and normalize text.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"/[ur]/[A-Za-z0-9_-]+\", \"\", text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+|#[A-Za-z0-9_]+\", \"\", text)\n",
    "    text = re.sub(r\"\\[deleted\\]|\\[removed\\]\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s!?]\", \" \", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def advanced_preprocess(text: str) -> str:\n",
    "    \"\"\"Comprehensive text preprocessing for mental health text.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    text = clean_social_text(text.lower())\n",
    "\n",
    "    contractions = {\n",
    "        \"won't\": \"will not\", \"can't\": \"cannot\", \"n't\": \" not\", \"'re\": \" are\",\n",
    "        \"'ve\": \" have\", \"'ll\": \" will\", \"'d\": \" would\", \"'m\": \" am\"\n",
    "    }\n",
    "    for c, e in contractions.items():\n",
    "        text = text.replace(c, e)\n",
    "\n",
    "    words = text.split()\n",
    "    cleaned = [\n",
    "        w for w in words\n",
    "        if (w in PRESERVE_KEYWORDS or w not in MENTAL_STOPWORDS) and len(w) > 1\n",
    "    ]\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "def lemmatize_text(text: str) -> str:\n",
    "    \"\"\"Lemmatize using spaCy or NLTK.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    if nlp:\n",
    "        doc = nlp(text)\n",
    "        return \" \".join(\n",
    "            token.lemma_ if token.lemma_ != \"-PRON-\" else token.text\n",
    "            for token in doc if not token.is_space\n",
    "        )\n",
    "    else:\n",
    "        return \" \".join(lemmatizer.lemmatize(w) for w in text.split())\n",
    "\n",
    "def full_clean_pipeline(text: str) -> str:\n",
    "    \"\"\"Full text normalization pipeline.\"\"\"\n",
    "    cleaned = advanced_preprocess(text)\n",
    "    lemmatized = lemmatize_text(cleaned)\n",
    "    final = re.sub(r\"\\s+\", \" \", lemmatized).strip()\n",
    "    return final if final else \"empty_text\"\n",
    "\n",
    "# ==========================================\n",
    "# BATCH PROCESSOR\n",
    "# ==========================================\n",
    "def batch_clean_texts(text_series: pd.Series, batch_size: int = 1000) -> pd.Series:\n",
    "    \"\"\"Efficient batch cleaning with progress tracking.\"\"\"\n",
    "    processed = []\n",
    "    n = len(text_series)\n",
    "    total_batches = (n // batch_size) + (1 if n % batch_size else 0)\n",
    "    print(f\"üßπ Cleaning {n:,} texts in {total_batches} batches of {batch_size}...\")\n",
    "    start = time.time()\n",
    "    for i in range(0, n, batch_size):\n",
    "        batch = text_series.iloc[i:i+batch_size]\n",
    "        processed.extend(batch.progress_apply(full_clean_pipeline))\n",
    "    print(f\"‚úÖ Completed in {time.time()-start:.1f}s\")\n",
    "    return pd.Series(processed, index=text_series.index)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "print(\"=\"*60)\n",
    "print(\"ENHANCED TEXT PREPROCESSING FOR MENTAL STRESS DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Detect text column\n",
    "text_cols = [c for c in stress.columns if stress[c].dtype == \"object\" and c not in [\"label\", \"subreddit\"]]\n",
    "if not text_cols:\n",
    "    raise ValueError(\"‚ö†Ô∏è No text columns found. Please verify your dataset.\")\n",
    "TEXT_COL = text_cols[0]\n",
    "print(f\"üìò Text column detected: '{TEXT_COL}'\")\n",
    "\n",
    "# Display sample before cleaning\n",
    "print(\"\\nüìÑ Sample Original Texts:\")\n",
    "for i, t in enumerate(stress[TEXT_COL].dropna().head(3), 1):\n",
    "    print(f\"{i}. {t[:100]}...\")\n",
    "\n",
    "# Run cleaning\n",
    "stress[\"clean_text\"] = batch_clean_texts(stress[TEXT_COL])\n",
    "\n",
    "# Display after cleaning\n",
    "print(\"\\nüßæ Sample Cleaned Texts:\")\n",
    "for i, (o, c) in enumerate(zip(stress[TEXT_COL].dropna().head(3),\n",
    "                               stress[\"clean_text\"].dropna().head(3)), 1):\n",
    "    print(f\"{i}. Original: {o[:80]}...\")\n",
    "    print(f\"   Cleaned:  {c[:80]}...\")\n",
    "\n",
    "# ==========================================\n",
    "# METRICS & SUMMARY\n",
    "# ==========================================\n",
    "orig_len = stress[TEXT_COL].astype(str).str.len().mean()\n",
    "clean_len = stress[\"clean_text\"].astype(str).str.len().mean()\n",
    "orig_words = stress[TEXT_COL].astype(str).str.split().str.len().mean()\n",
    "clean_words = stress[\"clean_text\"].astype(str).str.split().str.len().mean()\n",
    "\n",
    "print(\"\\nüßÆ CLEANING STATISTICS:\")\n",
    "print(f\"Average Original Length: {orig_len:.1f} chars\")\n",
    "print(f\"Average Cleaned Length:  {clean_len:.1f} chars\")\n",
    "print(f\"Length Reduction:        {(1 - clean_len/orig_len)*100:.1f}%\")\n",
    "print(f\"Average Original Words:  {orig_words:.1f}\")\n",
    "print(f\"Average Cleaned Words:   {clean_words:.1f}\")\n",
    "print(f\"Word Reduction:          {(1 - clean_words/orig_words)*100:.1f}%\")\n",
    "\n",
    "empty_texts = (stress[\"clean_text\"] == \"empty_text\").sum()\n",
    "if empty_texts > 0:\n",
    "    print(f\"‚ö†Ô∏è {empty_texts} rows resulted in empty text after cleaning.\")\n",
    "\n",
    "# ==========================================\n",
    "# SAVE CONFIGURATION\n",
    "# ==========================================\n",
    "config = {\n",
    "    \"stopwords_count\": len(MENTAL_STOPWORDS),\n",
    "    \"preserved_keywords\": sorted(list(PRESERVE_KEYWORDS)),\n",
    "    \"text_column\": TEXT_COL,\n",
    "    \"lemmatization\": LEMMATIZER,\n",
    "    \"settings\": {\n",
    "        \"remove_digits\": True,\n",
    "        \"preserve_emphasis\": True,\n",
    "        \"min_word_length\": 2\n",
    "    }\n",
    "}\n",
    "with open(\"preprocessors/text_preprocessing_config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(\"\\nüìÅ Configuration saved ‚Üí preprocessors/text_preprocessing_config.json\")\n",
    "\n",
    "print(f\"\\n‚úÖ Text preprocessing complete! New column 'clean_text' created.\")\n",
    "print(f\"Final dataset shape: {stress.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7878df6b-24e8-43c7-9ed7-fbff67b5bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Checking & Downloading NLTK Resources...\n",
      "‚úÖ punkt already available\n",
      "‚úÖ punkt_tab already available\n",
      "‚úÖ stopwords already available\n",
      "‚¨áÔ∏è Downloading wordnet ...\n",
      "‚úÖ wordnet downloaded successfully\n",
      "‚úÖ words already available\n",
      "‚úÖ averaged_perceptron_tagger already available\n",
      "‚úÖ maxent_ne_chunker already available\n",
      "‚¨áÔ∏è Downloading vader_lexicon ...\n",
      "‚úÖ vader_lexicon downloaded successfully\n",
      "\n",
      "‚úÖ All NLTK resources ready!\n",
      "\n",
      "‚úÖ spaCy model 'en_core_web_sm' loaded successfully\n",
      "\n",
      "üîß Environment Initialization Complete\n",
      "NLTK + spaCy (optional) are ready for NLP tasks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ‚öôÔ∏è ENVIRONMENT SETUP - NLP DEPENDENCIES\n",
    "# ==========================================\n",
    "import ssl\n",
    "import nltk\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# --- Fix SSL issues (for Mac / older Python builds) ---\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# --- Required NLTK resources ---\n",
    "nltk_resources = {\n",
    "    \"tokenizers\": [\"punkt\", \"punkt_tab\"],\n",
    "    \"corpora\": [\"stopwords\", \"wordnet\", \"words\"],\n",
    "    \"taggers\": [\"averaged_perceptron_tagger\"],\n",
    "    \"chunkers\": [\"maxent_ne_chunker\"],\n",
    "    \"sentiment\": [\"vader_lexicon\"]\n",
    "}\n",
    "\n",
    "print(\"üì¶ Checking & Downloading NLTK Resources...\")\n",
    "for category, resources in nltk_resources.items():\n",
    "    for resource in resources:\n",
    "        try:\n",
    "            nltk.data.find(f\"{category}/{resource}\")\n",
    "            print(f\"‚úÖ {resource} already available\")\n",
    "        except LookupError:\n",
    "            print(f\"‚¨áÔ∏è Downloading {resource} ...\")\n",
    "            nltk.download(resource, quiet=True)\n",
    "            print(f\"‚úÖ {resource} downloaded successfully\")\n",
    "\n",
    "print(\"\\n‚úÖ All NLTK resources ready!\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# üß† OPTIONAL: INSTALL & LOAD spaCy MODEL\n",
    "# ==========================================\n",
    "USE_SPACY = True  # Set False if you want to skip spaCy setup for lightweight runs\n",
    "\n",
    "if USE_SPACY:\n",
    "    try:\n",
    "        import spacy\n",
    "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"tok2vec\", \"tagger\", \"attribute_ruler\"])\n",
    "        print(\"‚úÖ spaCy model 'en_core_web_sm' loaded successfully\")\n",
    "    except OSError:\n",
    "        print(\"‚ö†Ô∏è spaCy model not found. Attempting to download...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "        import spacy\n",
    "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"tok2vec\", \"tagger\", \"attribute_ruler\"])\n",
    "        print(\"‚úÖ spaCy model 'en_core_web_sm' downloaded and loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è spaCy could not be initialized: {e}\")\n",
    "        nlp = None\n",
    "else:\n",
    "    nlp = None\n",
    "    print(\"‚öôÔ∏è Skipping spaCy setup (USE_SPACY=False)\")\n",
    "\n",
    "# ==========================================\n",
    "# ‚úÖ SUMMARY\n",
    "# ==========================================\n",
    "print(\"\\nüîß Environment Initialization Complete\")\n",
    "print(\"NLTK + spaCy (optional) are ready for NLP tasks.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382b231f-abf1-49cd-82ac-55327a02ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XGBoost available\n",
      "‚úÖ LightGBM available\n",
      "‚úÖ CatBoost available\n",
      "‚úÖ TextStat available\n",
      "‚úÖ VaderSentiment available\n",
      "\n",
      "üéØ All imports and dependencies successfully initialized!\n",
      "\n",
      "üì¶ Library Versions:\n",
      "  numpy:      1.26.4\n",
      "  pandas:     2.3.1\n",
      "  scikit-learn: 1.7.1\n",
      "  nltk:       3.9.1\n",
      "  spacy:      3.8.7\n",
      "  xgboost:    3.1.1\n",
      "  lightgbm:   4.6.0\n",
      "  catboost:   1.2.8\n",
      "\n",
      "‚úÖ Environment fully configured and ready for model training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ‚öôÔ∏è MODEL ENVIRONMENT & IMPORTS\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# Core Data Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================\n",
    "# NLP & TEXT PROCESSING\n",
    "# ==========================================\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# ==========================================\n",
    "# FEATURE EXTRACTION & VECTORIZATION\n",
    "# ==========================================\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    ")\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "\n",
    "# ==========================================\n",
    "# MODEL SELECTION & EVALUATION\n",
    "# ==========================================\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, cross_val_score, \n",
    "    cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    matthews_corrcoef, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ==========================================\n",
    "# MACHINE LEARNING MODELS\n",
    "# ==========================================\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, RidgeClassifier, SGDClassifier\n",
    ")\n",
    "from sklearn.naive_bayes import (\n",
    "    MultinomialNB, ComplementNB, BernoulliNB\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, AdaBoostClassifier, \n",
    "    ExtraTreesClassifier, GradientBoostingClassifier,\n",
    "    StackingClassifier, VotingClassifier, BaggingClassifier,\n",
    "    HistGradientBoostingClassifier\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# ADVANCED MODELS (XGBoost / LightGBM / CatBoost)\n",
    "# ==========================================\n",
    "def safe_import(package_name, import_name=None):\n",
    "    \"\"\"Safely import a package, installing if necessary.\"\"\"\n",
    "    try:\n",
    "        module = __import__(package_name if import_name is None else import_name)\n",
    "        print(f\"‚úÖ {package_name} available\")\n",
    "        return module\n",
    "    except ImportError:\n",
    "        print(f\"‚¨áÔ∏è Installing {package_name}...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        module = __import__(package_name if import_name is None else import_name)\n",
    "        print(f\"‚úÖ {package_name} installed successfully\")\n",
    "        return module\n",
    "\n",
    "# ---- XGBoost ----\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"‚úÖ XGBoost available\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not installed\")\n",
    "\n",
    "# ---- LightGBM ----\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "    print(\"‚úÖ LightGBM available\")\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è LightGBM not installed\")\n",
    "\n",
    "# ---- CatBoost ----\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "    print(\"‚úÖ CatBoost available\")\n",
    "except ImportError:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è CatBoost not installed\")\n",
    "\n",
    "# ==========================================\n",
    "# TEXT ANALYSIS UTILITIES\n",
    "# ==========================================\n",
    "# ---- TextStat (Readability Scores) ----\n",
    "try:\n",
    "    from textstat import flesch_reading_ease, flesch_kincaid_grade\n",
    "    TEXTSTAT_AVAILABLE = True\n",
    "    print(\"‚úÖ TextStat available\")\n",
    "except ImportError:\n",
    "    TEXTSTAT_AVAILABLE = False\n",
    "    print(\"‚¨áÔ∏è Installing TextStat...\")\n",
    "    textstat = safe_import(\"textstat\")\n",
    "    from textstat import flesch_reading_ease, flesch_kincaid_grade\n",
    "    TEXTSTAT_AVAILABLE = True\n",
    "\n",
    "# ---- Vader Sentiment ----\n",
    "try:\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    VADER_AVAILABLE = True\n",
    "    print(\"‚úÖ VaderSentiment available\")\n",
    "except ImportError:\n",
    "    VADER_AVAILABLE = False\n",
    "    print(\"‚¨áÔ∏è Installing VaderSentiment...\")\n",
    "    vaderSentiment = safe_import(\"vaderSentiment\")\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    VADER_AVAILABLE = True\n",
    "\n",
    "# ==========================================\n",
    "# COMPLETION LOG\n",
    "# ==========================================\n",
    "print(\"\\nüéØ All imports and dependencies successfully initialized!\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# VERSION SUMMARY\n",
    "# ==========================================\n",
    "import sklearn\n",
    "print(\"üì¶ Library Versions:\")\n",
    "print(f\"  numpy:      {np.__version__}\")\n",
    "print(f\"  pandas:     {pd.__version__}\")\n",
    "print(f\"  scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"  nltk:       {nltk.__version__}\")\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    print(f\"  spacy:      {spacy.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"  spacy:      Not Installed\")\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    import xgboost\n",
    "    print(f\"  xgboost:    {xgboost.__version__}\")\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    import lightgbm\n",
    "    print(f\"  lightgbm:   {lightgbm.__version__}\")\n",
    "if CATBOOST_AVAILABLE:\n",
    "    import catboost\n",
    "    print(f\"  catboost:   {catboost.__version__}\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment fully configured and ready for model training!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bbc2c-c84f-415f-89a5-6ad69460d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574350cd-cce8-4499-ade1-da2ae0b180e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf4473-2434-477a-ba86-e73954ff4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d748e2a9-5c5a-413b-a9bb-00366601b739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ High-Performance Text Preprocessor initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ‚öôÔ∏è OPTIMIZED HIGH-PERFORMANCE TEXT PREPROCESSOR\n",
    "# ==========================================\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sentiment Analyzer check\n",
    "if \"VADER_AVAILABLE\" in globals() and VADER_AVAILABLE:\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    USE_VADER = True\n",
    "else:\n",
    "    USE_VADER = False\n",
    "\n",
    "class HighPerformanceTextPreprocessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize with advanced stress and emotion lexicons.\"\"\"\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "        self.sentiment_analyzer = SentimentIntensityAnalyzer() if USE_VADER else None\n",
    "\n",
    "        # ===== Mental Health Lexicons =====\n",
    "        self.stress_keywords = {\n",
    "            'stress','stressed','stressing','stressful','pressure','pressured','overwhelming',\n",
    "            'overwhelm','overwhelmed','anxiety','anxious','worried','worry','panic','fear',\n",
    "            'nervous','afraid','scared','terrified','depression','depressed','sad','hopeless',\n",
    "            'helpless','miserable','angry','frustrated','tired','exhausted','fatigue','burnout',\n",
    "            'sleepless','insomnia','pain','crying','breakdown','broken','hurt','lost','trapped',\n",
    "            'suffocating','drowning','confused','hurt','worse','shattered'\n",
    "        }\n",
    "\n",
    "        self.positive_keywords = {\n",
    "            'happy','joy','joyful','excited','amazing','wonderful','fantastic','great','excellent',\n",
    "            'beautiful','calm','peaceful','relaxed','content','satisfied','cheerful','optimistic',\n",
    "            'grateful','thankful','love','loving','supported','helped','better','healing','hopeful'\n",
    "        }\n",
    "\n",
    "        # Exclude mental health terms from stopwords\n",
    "        self.stop_words = self.stop_words - self.stress_keywords - self.positive_keywords\n",
    "\n",
    "        # Regex pre-compilation for faster processing\n",
    "        self.url_pattern = re.compile(r\"http[s]?://[^\\s]+|www\\.[^\\s]+\", re.I)\n",
    "        self.non_alphanum = re.compile(r\"[^a-zA-Z0-9\\s!?.,;-]\", re.I)\n",
    "        self.multi_space = re.compile(r\"\\s+\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # üß† TEXT CLEANING\n",
    "    # ==========================================\n",
    "    def clean_text_advanced(self, text: str) -> str:\n",
    "        \"\"\"Cleans and lemmatizes text efficiently while preserving context.\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "\n",
    "        text = text.lower()\n",
    "        text = self.url_pattern.sub(\" url \", text)\n",
    "        text = re.sub(r\"[!]{2,}\", \"!!\", text)\n",
    "        text = re.sub(r\"[?]{2,}\", \"??\", text)\n",
    "        text = self.non_alphanum.sub(\" \", text)\n",
    "        text = self.multi_space.sub(\" \", text).strip()\n",
    "\n",
    "        # Tokenize\n",
    "        try:\n",
    "            tokens = word_tokenize(text)\n",
    "        except:\n",
    "            tokens = text.split()\n",
    "\n",
    "        processed = []\n",
    "        for token in tokens:\n",
    "            if len(token) < 2 and token not in {\"i\", \"!\", \"?\"}:\n",
    "                continue\n",
    "\n",
    "            if token in self.stress_keywords or token in self.positive_keywords:\n",
    "                processed.append(token)\n",
    "            elif token not in self.stop_words:\n",
    "                try:\n",
    "                    processed.append(self.lemmatizer.lemmatize(token))\n",
    "                except:\n",
    "                    processed.append(token)\n",
    "            elif token in {\"i\", \"me\", \"my\", \"no\", \"not\", \"!\", \"?\"}:\n",
    "                processed.append(token)\n",
    "\n",
    "        return \" \".join(processed)\n",
    "\n",
    "    # ==========================================\n",
    "    # üß© FEATURE EXTRACTION\n",
    "    # ==========================================\n",
    "    def extract_advanced_features(self, text: str) -> dict:\n",
    "        \"\"\"Extracts robust linguistic, emotional, and contextual features.\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return {f\"feature_{i}\": 0 for i in range(25)}\n",
    "\n",
    "        text = text.lower()\n",
    "        words = text.split()\n",
    "        word_count = len(words)\n",
    "        char_count = len(text)\n",
    "        features = {}\n",
    "\n",
    "        # Basic structural stats\n",
    "        features[\"char_count\"] = char_count\n",
    "        features[\"word_count\"] = word_count\n",
    "        features[\"avg_word_length\"] = np.mean([len(w) for w in words]) if words else 0\n",
    "\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        features[\"sentence_count\"] = len(sentences)\n",
    "        features[\"avg_sentence_length\"] = word_count / max(len(sentences), 1)\n",
    "\n",
    "        # Keyword-based emotional density\n",
    "        stress_count = sum(word in self.stress_keywords for word in words)\n",
    "        positive_count = sum(word in self.positive_keywords for word in words)\n",
    "        features[\"stress_density\"] = stress_count / max(word_count, 1)\n",
    "        features[\"positive_density\"] = positive_count / max(word_count, 1)\n",
    "        features[\"emotional_polarity\"] = features[\"positive_density\"] - features[\"stress_density\"]\n",
    "\n",
    "        # Intensity & negation\n",
    "        intensity_words = [\"very\",\"extremely\",\"really\",\"so\",\"too\",\"completely\",\"totally\",\"absolutely\"]\n",
    "        negation_words = [\"not\",\"no\",\"never\",\"nothing\",\"nobody\",\"none\",\"cant\",\"cannot\",\"wont\",\"dont\"]\n",
    "        features[\"intensity_ratio\"] = sum(text.count(w) for w in intensity_words) / max(word_count, 1)\n",
    "        features[\"negation_ratio\"] = sum(text.count(w) for w in negation_words) / max(word_count, 1)\n",
    "\n",
    "        # Pronoun & punctuation\n",
    "        pronouns = [\" i \", \" me \", \" my \", \" myself \"]\n",
    "        features[\"first_person_ratio\"] = sum(text.count(p) for p in pronouns) / max(word_count, 1)\n",
    "        features[\"exclamation_ratio\"] = text.count(\"!\") / max(char_count, 1)\n",
    "        features[\"question_ratio\"] = text.count(\"?\") / max(char_count, 1)\n",
    "\n",
    "        # Sentiment analysis\n",
    "        if USE_VADER and self.sentiment_analyzer:\n",
    "            try:\n",
    "                s = self.sentiment_analyzer.polarity_scores(text)\n",
    "                features.update({\n",
    "                    \"sentiment_positive\": s[\"pos\"],\n",
    "                    \"sentiment_negative\": s[\"neg\"],\n",
    "                    \"sentiment_neutral\": s[\"neu\"],\n",
    "                    \"sentiment_compound\": s[\"compound\"],\n",
    "                })\n",
    "            except:\n",
    "                features.update({\n",
    "                    \"sentiment_positive\": 0.0,\n",
    "                    \"sentiment_negative\": 0.0,\n",
    "                    \"sentiment_neutral\": 1.0,\n",
    "                    \"sentiment_compound\": 0.0,\n",
    "                })\n",
    "        else:\n",
    "            features[\"sentiment_positive\"] = positive_count / max(word_count, 1)\n",
    "            features[\"sentiment_negative\"] = stress_count / max(word_count, 1)\n",
    "            features[\"sentiment_neutral\"] = 1 - features[\"sentiment_positive\"] - features[\"sentiment_negative\"]\n",
    "            features[\"sentiment_compound\"] = features[\"sentiment_positive\"] - features[\"sentiment_negative\"]\n",
    "\n",
    "        # Contextual domains\n",
    "        work_terms = [\"work\", \"job\", \"office\", \"project\", \"deadline\"]\n",
    "        family_terms = [\"family\", \"husband\", \"wife\", \"parents\", \"children\", \"home\"]\n",
    "        health_terms = [\"health\", \"doctor\", \"pain\", \"sick\", \"hospital\", \"medicine\"]\n",
    "        features[\"work_context\"] = sum(text.count(w) for w in work_terms) / max(word_count, 1)\n",
    "        features[\"family_context\"] = sum(text.count(w) for w in family_terms) / max(word_count, 1)\n",
    "        features[\"health_context\"] = sum(text.count(w) for w in health_terms) / max(word_count, 1)\n",
    "\n",
    "        return features\n",
    "\n",
    "print(\"‚úÖ High-Performance Text Preprocessor initialized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657ac453-8f88-4452-940e-a542ba122628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 6 optimized vectorizers:\n",
      "   ‚Ä¢ tfidf_unigram   | n-gram: (1, 1) | max_features: 10000\n",
      "   ‚Ä¢ tfidf_bigram    | n-gram: (1, 2) | max_features: 15000\n",
      "   ‚Ä¢ tfidf_trigram   | n-gram: (1, 3) | max_features: 20000\n",
      "   ‚Ä¢ count_unigram   | n-gram: (1, 1) | max_features: 8000\n",
      "   ‚Ä¢ count_bigram    | n-gram: (1, 2) | max_features: 12000\n",
      "   ‚Ä¢ tfidf_char      | n-gram: (3, 5) | max_features: 8000\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üß© ADVANCED VECTORIZER CREATOR\n",
    "# ==========================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def create_advanced_vectorizers(custom_stopwords=None):\n",
    "    \"\"\"\n",
    "    Create a suite of optimized vectorizers for mental health text analysis.\n",
    "    \n",
    "    Includes: TF-IDF (unigram‚Äìtrigram), character-level, and CountVectorizers.\n",
    "    All settings tuned for emotional and linguistic context retention.\n",
    "    \"\"\"\n",
    "    stop_words = custom_stopwords if custom_stopwords else 'english'\n",
    "    \n",
    "    vectorizers = {\n",
    "        # TF-IDF - Unigrams (core semantics)\n",
    "        'tfidf_unigram': TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=3,\n",
    "            max_df=0.95,\n",
    "            stop_words=stop_words,\n",
    "            sublinear_tf=True,\n",
    "            use_idf=True,\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode'\n",
    "        ),\n",
    "\n",
    "        # TF-IDF - Bigrams (captures sentiment context like \"feel bad\")\n",
    "        'tfidf_bigram': TfidfVectorizer(\n",
    "            max_features=15000,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.9,\n",
    "            stop_words=stop_words,\n",
    "            sublinear_tf=True,\n",
    "            use_idf=True,\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode'\n",
    "        ),\n",
    "\n",
    "        # TF-IDF - Trigrams (captures phrases like \"hard to breathe\")\n",
    "        'tfidf_trigram': TfidfVectorizer(\n",
    "            max_features=20000,\n",
    "            ngram_range=(1, 3),\n",
    "            min_df=2,\n",
    "            max_df=0.9,\n",
    "            stop_words=stop_words,\n",
    "            sublinear_tf=True,\n",
    "            use_idf=True,\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode'\n",
    "        ),\n",
    "\n",
    "        # Count Vectorizer - Unigram (raw frequency baseline)\n",
    "        'count_unigram': CountVectorizer(\n",
    "            max_features=8000,\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=3,\n",
    "            max_df=0.95,\n",
    "            stop_words=stop_words,\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode'\n",
    "        ),\n",
    "\n",
    "        # Count Vectorizer - Bigram (frequency with light context)\n",
    "        'count_bigram': CountVectorizer(\n",
    "            max_features=12000,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.9,\n",
    "            stop_words=stop_words,\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode'\n",
    "        ),\n",
    "\n",
    "        # TF-IDF Character-level (captures spelling/emotional emphasis like \"soooo tired\")\n",
    "        'tfidf_char': TfidfVectorizer(\n",
    "            max_features=8000,\n",
    "            analyzer='char',\n",
    "            ngram_range=(3, 5),\n",
    "            min_df=3,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(vectorizers)} optimized vectorizers:\")\n",
    "    for name, vec in vectorizers.items():\n",
    "        ngram_info = f\"{vec.ngram_range}\" if hasattr(vec, \"ngram_range\") else \"N/A\"\n",
    "        print(f\"   ‚Ä¢ {name:<15} | n-gram: {ngram_info} | max_features: {vec.max_features}\")\n",
    "    \n",
    "    return vectorizers\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# ‚öôÔ∏è Instantiate Vectorizers\n",
    "# ==========================================\n",
    "vectorizers = create_advanced_vectorizers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7ff6ff-e7f1-4b05-8168-96d25929ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 6 novel vectorizers.\n",
      "‚úÖ Created 2 ensemble vectorizers.\n",
      "\n",
      "üì¶ Added 7 novel vectorizers:\n",
      "   ‚Ä¢ bow_binary\n",
      "   ‚Ä¢ bow_freq\n",
      "   ‚Ä¢ tfidf_sublinear\n",
      "   ‚Ä¢ hybrid_char_word\n",
      "   ‚Ä¢ mental_health_focused\n",
      "   ‚Ä¢ weighted_tfidf\n",
      "   ‚Ä¢ custom_stress\n",
      "\n",
      "üîó Added 2 ensemble vectorizers:\n",
      "   ‚Ä¢ ensemble_tfidf\n",
      "   ‚Ä¢ count_tfidf_ensemble\n",
      "\n",
      "‚úÖ Total vectorizers now available: 15\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üß© NOVEL, BoW & ENSEMBLE VECTORIZERS\n",
    "# ==========================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# ==========================================\n",
    "# üìö CREATE NOVEL VECTORIZERS\n",
    "# ==========================================\n",
    "def create_novel_vectorizers():\n",
    "    \"\"\"Create novel and baseline vectorization approaches (BoW, hybrid, domain-specific).\"\"\"\n",
    "    \n",
    "    novel_vectorizers = {\n",
    "        # --- Baseline Bag of Words (Binary & Frequency) ---\n",
    "        'bow_binary': CountVectorizer(\n",
    "            max_features=8000, ngram_range=(1, 1),\n",
    "            min_df=3, max_df=0.95, stop_words='english', binary=True\n",
    "        ),\n",
    "        'bow_freq': CountVectorizer(\n",
    "            max_features=10000, ngram_range=(1, 1),\n",
    "            min_df=2, max_df=0.95, stop_words='english', binary=False\n",
    "        ),\n",
    "\n",
    "        # --- Novel TF-IDF Variant ---\n",
    "        'tfidf_sublinear': TfidfVectorizer(\n",
    "            max_features=12000, ngram_range=(1, 2),\n",
    "            min_df=2, max_df=0.85, stop_words='english',\n",
    "            sublinear_tf=True, use_idf=True, norm='l1'\n",
    "        ),\n",
    "\n",
    "        # --- Hybrid Char + Word TF-IDF ---\n",
    "        'hybrid_char_word': FeatureUnion([\n",
    "            ('word_tfidf', TfidfVectorizer(\n",
    "                max_features=6000, ngram_range=(1, 2),\n",
    "                min_df=3, stop_words='english')),\n",
    "            ('char_tfidf', TfidfVectorizer(\n",
    "                max_features=4000, analyzer='char_wb',\n",
    "                ngram_range=(3, 5), min_df=3))\n",
    "        ]),\n",
    "\n",
    "        # --- Domain-Focused Mental Health Vocabulary ---\n",
    "        'mental_health_focused': TfidfVectorizer(\n",
    "            max_features=8000, ngram_range=(1, 2),\n",
    "            min_df=2, max_df=0.9,\n",
    "            stop_words=['the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by']\n",
    "        ),\n",
    "\n",
    "        # --- Weighted TF-IDF (emotional emphasis) ---\n",
    "        'weighted_tfidf': TfidfVectorizer(\n",
    "            max_features=10000, ngram_range=(1, 2),\n",
    "            min_df=2, max_df=0.9,\n",
    "            stop_words='english', token_pattern=r'\\b\\w+\\b',\n",
    "            lowercase=True, use_idf=True, smooth_idf=True\n",
    "        )\n",
    "    }\n",
    "    print(f\"‚úÖ Created {len(novel_vectorizers)} novel vectorizers.\")\n",
    "    return novel_vectorizers\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# üß© CREATE ENSEMBLE VECTORIZERS\n",
    "# ==========================================\n",
    "def create_ensemble_vectorizers():\n",
    "    \"\"\"Create ensemble-based feature unions of multiple vectorizers.\"\"\"\n",
    "    ensemble_vectorizers = {\n",
    "        # --- Multi-TFIDF Ensemble (uni+bi+tri) ---\n",
    "        'ensemble_tfidf': FeatureUnion([\n",
    "            ('tfidf_uni', TfidfVectorizer(max_features=4000, ngram_range=(1, 1), min_df=3, stop_words='english')),\n",
    "            ('tfidf_bi', TfidfVectorizer(max_features=4000, ngram_range=(2, 2), min_df=2, stop_words='english')),\n",
    "            ('tfidf_tri', TfidfVectorizer(max_features=2000, ngram_range=(3, 3), min_df=2, stop_words='english'))\n",
    "        ]),\n",
    "\n",
    "        # --- Count + TF-IDF Ensemble ---\n",
    "        'count_tfidf_ensemble': FeatureUnion([\n",
    "            ('count', CountVectorizer(max_features=5000, ngram_range=(1, 1), min_df=3, stop_words='english')),\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2, stop_words='english'))\n",
    "        ])\n",
    "    }\n",
    "    print(f\"‚úÖ Created {len(ensemble_vectorizers)} ensemble vectorizers.\")\n",
    "    return ensemble_vectorizers\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# üß† CUSTOM STRESS-FOCUSED VECTORIZER\n",
    "# ==========================================\n",
    "class CustomStressVectorizer:\n",
    "    \"\"\"A novel vectorizer combining TF-IDF with stress-specific emotional features.\"\"\"\n",
    "\n",
    "    def __init__(self, max_features=8000, scaler=None):\n",
    "        self.max_features = max_features\n",
    "        self.scaler = scaler or StandardScaler()\n",
    "        self.vectorizer = None\n",
    "\n",
    "        # Domain-specific lexicons\n",
    "        self.stress_keywords = [\n",
    "            'stress','anxiety','panic','worry','fear','overwhelm','pressure',\n",
    "            'depression','sad','angry','frustrated','tired','exhausted','burnout',\n",
    "            'breakdown','crisis','help','therapy','medication','hopeless','helpless',\n",
    "            'lonely','isolated','afraid','scared'\n",
    "        ]\n",
    "        self.positive_keywords = [\n",
    "            'happy','joy','peaceful','calm','relaxed','wonderful','amazing',\n",
    "            'fantastic','love','blessed','grateful','optimistic','confident',\n",
    "            'energetic','motivated','successful'\n",
    "        ]\n",
    "        self.intensity_words = [\n",
    "            'very','extremely','really','so','too','quite','rather','completely',\n",
    "            'totally','absolutely','incredibly','tremendously'\n",
    "        ]\n",
    "\n",
    "    def _create_custom_features(self, texts):\n",
    "        \"\"\"Extract stress-related density, polarity, punctuation, and personal intensity features.\"\"\"\n",
    "        features = []\n",
    "        for text in texts:\n",
    "            if not isinstance(text, str):\n",
    "                text = ''\n",
    "            text_lower = text.lower()\n",
    "            word_count = max(len(text.split()), 1)\n",
    "\n",
    "            stress_count = sum(word in text_lower for word in self.stress_keywords)\n",
    "            positive_count = sum(word in text_lower for word in self.positive_keywords)\n",
    "            intensity_count = sum(word in text_lower for word in self.intensity_words)\n",
    "\n",
    "            personal_pronouns = [' i ', ' me ', ' my ', ' myself ']\n",
    "            personal_count = sum(text_lower.count(p) for p in personal_pronouns)\n",
    "\n",
    "            features.append({\n",
    "                'stress_keyword_density': stress_count / word_count,\n",
    "                'positive_keyword_density': positive_count / word_count,\n",
    "                'intensity_amplification': intensity_count / word_count,\n",
    "                'emotional_polarity': (positive_count - stress_count) / word_count,\n",
    "                'exclamation_ratio': text.count('!') / max(len(text), 1),\n",
    "                'question_ratio': text.count('?') / max(len(text), 1),\n",
    "                'personal_intensity': personal_count / word_count,\n",
    "            })\n",
    "        return pd.DataFrame(features)\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        \"\"\"Fit TF-IDF and combine with custom emotion features.\"\"\"\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=self.max_features - 100,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.9,\n",
    "            stop_words='english'\n",
    "        )\n",
    "        tfidf_features = self.vectorizer.fit_transform(texts)\n",
    "        custom_features = self._create_custom_features(texts)\n",
    "        scaled = self.scaler.fit_transform(custom_features)\n",
    "        return hstack([tfidf_features, csr_matrix(scaled)])\n",
    "\n",
    "    def transform(self, texts):\n",
    "        if self.vectorizer is None:\n",
    "            raise ValueError(\"CustomStressVectorizer must be fitted before transform.\")\n",
    "        tfidf_features = self.vectorizer.transform(texts)\n",
    "        custom_features = self._create_custom_features(texts)\n",
    "        scaled = self.scaler.transform(custom_features)\n",
    "        return hstack([tfidf_features, csr_matrix(scaled)])\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# üîó COMBINE ALL VECTORIZERS\n",
    "# ==========================================\n",
    "novel_vectorizers = create_novel_vectorizers()\n",
    "ensemble_vectorizers = create_ensemble_vectorizers()\n",
    "novel_vectorizers['custom_stress'] = CustomStressVectorizer(max_features=8000)\n",
    "\n",
    "# Merge with earlier `vectorizers` (TF-IDF & Count from previous cell)\n",
    "all_vectorizers = {**vectorizers, **novel_vectorizers, **ensemble_vectorizers}\n",
    "\n",
    "# Summary logs\n",
    "print(f\"\\nüì¶ Added {len(novel_vectorizers)} novel vectorizers:\")\n",
    "for n in novel_vectorizers.keys():\n",
    "    print(f\"   ‚Ä¢ {n}\")\n",
    "\n",
    "print(f\"\\nüîó Added {len(ensemble_vectorizers)} ensemble vectorizers:\")\n",
    "for n in ensemble_vectorizers.keys():\n",
    "    print(f\"   ‚Ä¢ {n}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total vectorizers now available: {len(all_vectorizers)}\")\n",
    "\n",
    "# Update main dictionary\n",
    "vectorizers = all_vectorizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c920f63-8703-4c9d-ac9f-a694385af771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Model Suite Assembled Successfully\n",
      "  ‚Ä¢ Total Models: 30\n",
      "  ‚Ä¢ Example: ['LogisticRegression', 'LogisticRegression_L1', 'RidgeClassifier', 'SGDClassifier', 'MultinomialNB', 'ComplementNB', 'BernoulliNB', 'RandomForest', 'ExtraTrees', 'GradientBoosting']\n",
      "  ‚Ä¢ XGBoost Available: True\n",
      "  ‚Ä¢ LightGBM Available: True\n",
      "  ‚Ä¢ CatBoost Available: True\n",
      "  ‚Ä¢ Includes DeepFeatureEnsemble, AdaptiveBoosting, StressFocusedEnsemble\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ü§ñ CELL 10 ‚Äî COMPLETE MODEL SUITE\n",
    "# ==========================================\n",
    "# Unified, self-contained registry of base, novel, and deep ensemble models\n",
    "# Run this after all imports & vectorizers are defined \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Core sklearn imports ---\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier,\n",
    "    AdaBoostClassifier, GradientBoostingClassifier,\n",
    "    BaggingClassifier, VotingClassifier\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# --- Optional gradient boosting libraries ---\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except Exception:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except Exception:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Base Model Factory\n",
    "# ------------------------------------------------------------\n",
    "def create_advanced_models():\n",
    "    \"\"\"Return well-configured traditional ML models.\"\"\"\n",
    "    models = {\n",
    "        # Linear Models\n",
    "        \"LogisticRegression\": LogisticRegression(C=1.0, max_iter=2000, random_state=42, class_weight=\"balanced\"),\n",
    "        \"LogisticRegression_L1\": LogisticRegression(\n",
    "            C=0.5, penalty=\"l1\", solver=\"liblinear\", max_iter=2000, random_state=42, class_weight=\"balanced\"\n",
    "        ),\n",
    "        \"RidgeClassifier\": RidgeClassifier(alpha=1.0),\n",
    "        \"SGDClassifier\": SGDClassifier(loss=\"hinge\", alpha=1e-4, max_iter=2000, random_state=42),\n",
    "\n",
    "        # Naive Bayes\n",
    "        \"MultinomialNB\": MultinomialNB(alpha=0.1),\n",
    "        \"ComplementNB\": ComplementNB(alpha=0.1),\n",
    "        \"BernoulliNB\": BernoulliNB(alpha=0.1),\n",
    "\n",
    "        # Trees\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=200, max_depth=15, random_state=42, class_weight=\"balanced\", n_jobs=-1\n",
    "        ),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(\n",
    "            n_estimators=200, max_depth=15, random_state=42, class_weight=\"balanced\", n_jobs=-1\n",
    "        ),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, max_depth=4, random_state=42),\n",
    "\n",
    "        # Others\n",
    "        \"LinearSVC\": LinearSVC(C=1.0, max_iter=2000, random_state=42),\n",
    "        \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=7, weights=\"distance\", n_jobs=-1),\n",
    "    }\n",
    "\n",
    "    # Optional libraries\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        models[\"XGBoost\"] = XGBClassifier(\n",
    "            n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42,\n",
    "            eval_metric=\"logloss\", use_label_encoder=False, n_jobs=-1\n",
    "        )\n",
    "    if LIGHTGBM_AVAILABLE:\n",
    "        models[\"LightGBM\"] = LGBMClassifier(\n",
    "            n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42,\n",
    "            class_weight=\"balanced\", n_jobs=-1\n",
    "        )\n",
    "    if CATBOOST_AVAILABLE:\n",
    "        models[\"CatBoost\"] = CatBoostClassifier(\n",
    "            iterations=200, learning_rate=0.1, depth=6, random_state=42,\n",
    "            auto_class_weights=\"Balanced\", verbose=False\n",
    "        )\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Novel / Ensemble Model Factory\n",
    "# ------------------------------------------------------------\n",
    "def create_novel_models():\n",
    "    novel = {\n",
    "        \"linear_stacking_voting\": VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"lr\", LogisticRegression(C=1.0, random_state=42)),\n",
    "                (\"ridge\", RidgeClassifier(alpha=0.5)),\n",
    "                (\"sgd\", SGDClassifier(alpha=1e-4, random_state=42))\n",
    "            ],\n",
    "            voting=\"hard\"\n",
    "        ),\n",
    "        \"ada_boost_tree\": AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=3), n_estimators=100, learning_rate=1.0, random_state=42\n",
    "        ),\n",
    "        \"bagging_lr\": BaggingClassifier(\n",
    "            estimator=LogisticRegression(random_state=42), n_estimators=20, random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        \"feature_selection_lr\": Pipeline([\n",
    "            (\"select\", SelectKBest(chi2, k=5000)),\n",
    "            (\"clf\", LogisticRegression(C=1.0, random_state=42))\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    novel[\"calibrated_rf\"] = CalibratedClassifierCV(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    novel[\"calibrated_svm\"] = CalibratedClassifierCV(LinearSVC(C=1.0, max_iter=2000, random_state=42))\n",
    "\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        novel[\"xgb_custom\"] = XGBClassifier(\n",
    "            n_estimators=150, learning_rate=0.15, max_depth=5, random_state=42,\n",
    "            eval_metric=\"logloss\", use_label_encoder=False, n_jobs=-1\n",
    "        )\n",
    "    return novel\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Deep & Custom Ensemble Classes\n",
    "# ------------------------------------------------------------\n",
    "class DeepFeatureEnsemble(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Multi-representation (word/char/syntax/emotion) ensemble with meta-learner.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.learners = {\n",
    "            \"word\": (TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words=\"english\"),\n",
    "                     LogisticRegression(max_iter=2000, random_state=42)),\n",
    "            \"char\": (TfidfVectorizer(max_features=3000, analyzer=\"char_wb\", ngram_range=(3, 5)),\n",
    "                     MultinomialNB(alpha=0.1)),\n",
    "            \"syntax\": (TfidfVectorizer(max_features=2000, ngram_range=(2, 3)),\n",
    "                       RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42)),\n",
    "            \"emotion\": (TfidfVectorizer(max_features=1000), SGDClassifier(alpha=1e-4, random_state=42))\n",
    "        }\n",
    "        self.meta = XGBClassifier(\n",
    "            n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42, eval_metric=\"logloss\"\n",
    "        ) if XGBOOST_AVAILABLE else LogisticRegression(C=0.5, random_state=42)\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        meta_feats = []\n",
    "        for name, (vec, model) in self.learners.items():\n",
    "            Xv = vec.fit_transform(X)\n",
    "            model.fit(Xv, y)\n",
    "            preds = model.predict_proba(Xv) if hasattr(model, \"predict_proba\") else model.predict(Xv)[:, None]\n",
    "            meta_feats.append(preds)\n",
    "        self.meta.fit(np.hstack(meta_feats), y)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"DeepFeatureEnsemble not fitted.\")\n",
    "        meta_feats = []\n",
    "        for vec, model in self.learners.values():\n",
    "            Xv = vec.transform(X)\n",
    "            preds = model.predict_proba(Xv) if hasattr(model, \"predict_proba\") else model.predict(Xv)[:, None]\n",
    "            meta_feats.append(preds)\n",
    "        return self.meta.predict(np.hstack(meta_feats))\n",
    "\n",
    "\n",
    "class AdaptiveBoosting(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Lightweight adaptive boosting emphasizing hard stress samples.\"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=8):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.models, self.weights = [], []\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        weights = np.ones(n) / n\n",
    "        for i in range(self.n_estimators):\n",
    "            idx = np.random.choice(n, n, p=weights)\n",
    "            Xs, ys = X[idx], y[idx]\n",
    "            base = [LogisticRegression(random_state=42+i),\n",
    "                    MultinomialNB(alpha=0.1),\n",
    "                    RandomForestClassifier(n_estimators=20, max_depth=5, random_state=42+i)][i % 3]\n",
    "            base.fit(Xs, ys)\n",
    "            preds = base.predict(X)\n",
    "            err = np.sum(weights * (preds != y))\n",
    "            if err == 0 or err >= 0.5:\n",
    "                continue\n",
    "            alpha = 0.5 * np.log((1 - err) / err)\n",
    "            weights *= np.exp(-alpha * (2 * y - 1) * (2 * preds - 1))\n",
    "            weights /= np.sum(weights)\n",
    "            self.models.append(base)\n",
    "            self.weights.append(alpha)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"AdaptiveBoosting not fitted.\")\n",
    "        agg = np.zeros(X.shape[0])\n",
    "        for m, w in zip(self.models, self.weights):\n",
    "            agg += w * (2 * m.predict(X) - 1)\n",
    "        return (agg > 0).astype(int)\n",
    "\n",
    "\n",
    "class StressFocusedEnsemble(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Stacking ensemble focused on stress classification.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base = {\n",
    "            \"nb\": MultinomialNB(alpha=0.05),\n",
    "            \"lr\": LogisticRegression(C=0.5, penalty=\"l1\", solver=\"liblinear\", random_state=42),\n",
    "            \"rf\": RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42)\n",
    "        }\n",
    "        self.meta = LogisticRegression(C=0.8, random_state=42)\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        base_preds = np.column_stack([\n",
    "            m.fit(X, y).predict_proba(X)[:, 1] if hasattr(m, \"predict_proba\") else m.fit(X, y).predict(X)\n",
    "            for m in self.base.values()\n",
    "        ])\n",
    "        self.meta.fit(base_preds, y)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        base_preds = np.column_stack([\n",
    "            m.predict_proba(X)[:, 1] if hasattr(m, \"predict_proba\") else m.predict(X)\n",
    "            for m in self.base.values()\n",
    "        ])\n",
    "        return self.meta.predict(base_preds)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Register All Models\n",
    "# ------------------------------------------------------------\n",
    "if \"models\" not in globals():\n",
    "    models = {}\n",
    "models.update(create_advanced_models())\n",
    "models.update(create_novel_models())\n",
    "models.update({\n",
    "    \"deep_feature_ensemble\": DeepFeatureEnsemble(),\n",
    "    \"adaptive_boosting\": AdaptiveBoosting(),\n",
    "    \"stress_focused_ensemble\": StressFocusedEnsemble()\n",
    "})\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Summary\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n‚úÖ Model Suite Assembled Successfully\")\n",
    "print(f\"  ‚Ä¢ Total Models: {len(models)}\")\n",
    "print(f\"  ‚Ä¢ Example: {list(models.keys())[:10]}\")\n",
    "print(f\"  ‚Ä¢ XGBoost Available: {XGBOOST_AVAILABLE}\")\n",
    "print(f\"  ‚Ä¢ LightGBM Available: {LIGHTGBM_AVAILABLE}\")\n",
    "print(f\"  ‚Ä¢ CatBoost Available: {CATBOOST_AVAILABLE}\")\n",
    "print(\"  ‚Ä¢ Includes DeepFeatureEnsemble, AdaptiveBoosting, StressFocusedEnsemble\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca759fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24d2403e-be24-4e99-aad3-4f5e9e441f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature engineering and data preparation functions ready!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üß© CELL 11 ‚Äî FEATURE ENGINEERING + DATA PREPARATION\n",
    "# ==========================================\n",
    "# This module builds cleaned text + linguistic features for ML & Deep ensembles.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ensure the AdvancedTextPreprocessor is already defined before this cell\n",
    "# It must implement:  clean_text_advanced()  and  extract_advanced_features()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üß† FEATURE ENGINEERING PIPELINE\n",
    "# ------------------------------------------------------------\n",
    "class FeatureEngineeringPipeline:\n",
    "    \"\"\"Pipeline for generating linguistic + numerical features.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.preprocessor = AdvancedTextPreprocessor()\n",
    "        self.feature_names = None\n",
    "\n",
    "    def create_features(self, texts):\n",
    "        \"\"\"Extract advanced linguistic and text-cleaning features.\"\"\"\n",
    "        linguistic_features = []\n",
    "        cleaned_texts = []\n",
    "\n",
    "        print(\"üîç Extracting linguistic features and cleaning texts...\")\n",
    "        for i, text in enumerate(texts):\n",
    "            if i % 1000 == 0 and i != 0:\n",
    "                print(f\"  ‚Ä¢ Processed {i}/{len(texts)} samples...\")\n",
    "\n",
    "            # Extract advanced linguistic (numerical) features\n",
    "            feats = self.preprocessor.extract_advanced_features(str(text))\n",
    "            linguistic_features.append(feats)\n",
    "\n",
    "            # Clean the text for model usage\n",
    "            cleaned = self.preprocessor.clean_text_advanced(str(text))\n",
    "            cleaned_texts.append(cleaned)\n",
    "\n",
    "        # Create dataframe of linguistic/numerical features\n",
    "        linguistic_df = pd.DataFrame(linguistic_features).fillna(0)\n",
    "        self.feature_names = list(linguistic_df.columns)\n",
    "\n",
    "        print(f\"‚úÖ Extracted {linguistic_df.shape[1]} linguistic features for {len(texts)} samples.\")\n",
    "        return cleaned_texts, linguistic_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìò BASIC DATA PREPARATION (text-only)\n",
    "# ------------------------------------------------------------\n",
    "def prepare_basic_data(df, text_col='clean_text', label_col='label', test_size=0.25):\n",
    "    \"\"\"Prepare dataset for text-only training (no numeric features).\"\"\"\n",
    "    print(\"\\nüìä Preparing dataset with basic preprocessing...\")\n",
    "\n",
    "    # Remove missing rows\n",
    "    df_clean = df.dropna(subset=[text_col, label_col]).copy()\n",
    "    print(f\"  ‚Ä¢ Removed {len(df) - len(df_clean)} rows with missing values.\")\n",
    "\n",
    "    # Clean text\n",
    "    preprocessor = AdvancedTextPreprocessor()\n",
    "    cleaned_texts = [preprocessor.clean_text_advanced(str(t)) for t in df_clean[text_col]]\n",
    "\n",
    "    # Encode labels\n",
    "    y = df_clean[label_col]\n",
    "    if y.dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "        mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        print(f\"  ‚Ä¢ Label mapping: {mapping}\")\n",
    "    else:\n",
    "        le = None\n",
    "        mapping = None\n",
    "\n",
    "    # Split into train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        cleaned_texts, y, test_size=test_size, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Data ready ‚Üí Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    return pd.Series(X_train), pd.Series(X_test), y_train, y_test, le, mapping\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üß† ADVANCED DATA PREPARATION (text + linguistic)\n",
    "# ------------------------------------------------------------\n",
    "def prepare_advanced_data(df, text_col='clean_text', label_col='label', test_size=0.25):\n",
    "    \"\"\"Prepare data with linguistic + advanced feature extraction.\"\"\"\n",
    "    print(\"\\nüìä Preparing dataset with advanced preprocessing and feature engineering...\")\n",
    "\n",
    "    # Remove missing rows\n",
    "    df_clean = df.dropna(subset=[text_col, label_col]).copy()\n",
    "    print(f\"  ‚Ä¢ Removed {len(df) - len(df_clean)} rows with missing values.\")\n",
    "\n",
    "    # Initialize feature pipeline\n",
    "    feature_pipe = FeatureEngineeringPipeline()\n",
    "    cleaned_texts, linguistic_df = feature_pipe.create_features(df_clean[text_col])\n",
    "\n",
    "    # Encode labels\n",
    "    y = df_clean[label_col]\n",
    "    if y.dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "        mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        print(f\"  ‚Ä¢ Label mapping: {mapping}\")\n",
    "    else:\n",
    "        le = None\n",
    "        mapping = None\n",
    "\n",
    "    # Split into train/test\n",
    "    X_text_train, X_text_test, X_feat_train, X_feat_test, y_train, y_test = train_test_split(\n",
    "        cleaned_texts, linguistic_df, y, test_size=test_size, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Data preparation complete:\")\n",
    "    print(f\"   ‚Ä¢ Training samples: {len(X_text_train)}\")\n",
    "    print(f\"   ‚Ä¢ Testing samples : {len(X_text_test)}\")\n",
    "    print(f\"   ‚Ä¢ Linguistic features: {linguistic_df.shape[1]} columns\")\n",
    "\n",
    "    return (\n",
    "        pd.Series(X_text_train), pd.Series(X_text_test),\n",
    "        X_feat_train, X_feat_test,\n",
    "        y_train, y_test, le, mapping, feature_pipe\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Feature engineering and data preparation functions ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "739ee9d4-c4e6-4869-8a11-5880e3925ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ‚öôÔ∏è ENHANCED ADVANCED TEXT PREPROCESSOR\n",
    "# ==========================================\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "class AdvancedTextPreprocessor:\n",
    "    \"\"\"\n",
    "    Unified high-performance text preprocessor:\n",
    "    - Cleans and normalizes text\n",
    "    - Extracts linguistic and emotional features\n",
    "    - Supports both clean_text() and extract_advanced_features()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "        # Mental health keyword sets\n",
    "        self.stress_keywords = {\n",
    "            'stress', 'stressed', 'pressure', 'overwhelm', 'anxiety', 'panic',\n",
    "            'fear', 'worry', 'tired', 'exhausted', 'sad', 'depression', 'hopeless'\n",
    "        }\n",
    "        self.positive_keywords = {\n",
    "            'happy', 'joy', 'peaceful', 'calm', 'love', 'grateful', 'relaxed',\n",
    "            'confident', 'optimistic', 'motivated', 'successful'\n",
    "        }\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # CLEANING\n",
    "    # --------------------------------------------------------------\n",
    "    def clean_text_advanced(self, text):\n",
    "        \"\"\"Performs advanced cleaning (used in feature extraction)\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+\", \"\", text)\n",
    "        text = re.sub(r\"[^a-z\\s!?.,;']\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        words = text.split()\n",
    "        cleaned = [self.lemmatizer.lemmatize(w) for w in words if w not in self.stop_words]\n",
    "        return \" \".join(cleaned)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Simplified cleaning (used in fallback/basic mode)\"\"\"\n",
    "        return self.clean_text_advanced(text)\n",
    "\n",
    "    def transform(self, texts):\n",
    "        \"\"\"Apply cleaning to a list/Series of texts\"\"\"\n",
    "        return [self.clean_text_advanced(t) for t in texts]\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # FEATURE EXTRACTION\n",
    "    # --------------------------------------------------------------\n",
    "    def extract_advanced_features(self, text):\n",
    "        \"\"\"Extracts linguistic, emotional, and contextual features\"\"\"\n",
    "        if not isinstance(text, str) or text.strip() == \"\":\n",
    "            return {f\"feature_{i}\": 0 for i in range(20)}\n",
    "\n",
    "        features = {}\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        words = text_lower.split()\n",
    "        features[\"char_count\"] = len(text_lower)\n",
    "        features[\"word_count\"] = len(words)\n",
    "        features[\"avg_word_length\"] = np.mean([len(w) for w in words]) if words else 0\n",
    "\n",
    "        # Stress/positive density\n",
    "        stress_count = sum(1 for w in words if w in self.stress_keywords)\n",
    "        pos_count = sum(1 for w in words if w in self.positive_keywords)\n",
    "        features[\"stress_density\"] = stress_count / max(len(words), 1)\n",
    "        features[\"positive_density\"] = pos_count / max(len(words), 1)\n",
    "        features[\"emotional_balance\"] = features[\"positive_density\"] - features[\"stress_density\"]\n",
    "\n",
    "        # Sentiment\n",
    "        sentiment = self.sentiment_analyzer.polarity_scores(text_lower)\n",
    "        features.update({\n",
    "            \"sent_pos\": sentiment[\"pos\"],\n",
    "            \"sent_neg\": sentiment[\"neg\"],\n",
    "            \"sent_neu\": sentiment[\"neu\"],\n",
    "            \"sent_compound\": sentiment[\"compound\"]\n",
    "        })\n",
    "\n",
    "        # Punctuation intensity\n",
    "        features[\"exclamation_count\"] = text_lower.count(\"!\")\n",
    "        features[\"question_count\"] = text_lower.count(\"?\")\n",
    "\n",
    "        # Personal references\n",
    "        features[\"first_person\"] = sum(text_lower.count(p) for p in [\" i \", \" me \", \" my \", \" mine \"])\n",
    "        features[\"first_person_ratio\"] = features[\"first_person\"] / max(len(words), 1)\n",
    "\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "121fac7a-d3bf-47c6-ad4e-ace6ef324fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß† ENHANCED MENTAL STRESS DETECTION ‚Äî DATA PREPARATION\n",
      "================================================================================\n",
      "üöÄ Attempting advanced data preparation...\n",
      "üìä Preparing dataset with advanced preprocessing and feature engineering...\n",
      "Removed 0 rows with missing text or labels.\n",
      "üîç Extracting linguistic features and cleaning texts...\n",
      "  Processed 1000/2838 samples\n",
      "  Processed 2000/2838 samples\n",
      "‚úÖ Created 14 linguistic features for 2838 samples.\n",
      "Label mapping: {'0': 0, '1': 1}\n",
      "‚úÖ Data prepared:\n",
      "  ‚Ä¢ Training: 2128 samples\n",
      "  ‚Ä¢ Testing: 710 samples\n",
      "  ‚Ä¢ Linguistic features: 14\n",
      "\n",
      "‚úÖ Advanced data preparation completed successfully!\n",
      "\n",
      "üìä DATA PREPARATION SUMMARY\n",
      "------------------------------------------------------------\n",
      "Training samples:       2,128\n",
      "Testing samples:        710\n",
      "Advanced features used: True\n",
      "Linguistic feature dims: 14\n",
      "Label encoder applied:  Yes\n",
      "------------------------------------------------------------\n",
      "‚úÖ Data successfully prepared and ready for vectorization & model training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üß† DATA PREPARATION EXECUTION CELL\n",
    "# ==========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üß† ENHANCED MENTAL STRESS DETECTION ‚Äî DATA PREPARATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Attempt advanced feature preparation first\n",
    "try:\n",
    "    print(\"üöÄ Attempting advanced data preparation...\")\n",
    "    (\n",
    "        X_text_train, X_text_test,\n",
    "        X_feat_train, X_feat_test,\n",
    "        y_train, y_test,\n",
    "        label_encoder, label_mapping,\n",
    "        feature_pipeline\n",
    "    ) = prepare_advanced_data(stress)\n",
    "\n",
    "    print(\"\\n‚úÖ Advanced data preparation completed successfully!\")\n",
    "    ADVANCED_FEATURES = True\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Fallback to basic preparation if advanced fails\n",
    "# -----------------------------------------------------------------\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Advanced preparation failed:\\n   ‚Ü≥ {e}\")\n",
    "    print(\"üîÑ Falling back to basic preparation...\")\n",
    "\n",
    "    try:\n",
    "        (\n",
    "            X_text_train, X_text_test,\n",
    "            y_train, y_test,\n",
    "            label_encoder, label_mapping\n",
    "        ) = prepare_basic_data(stress)\n",
    "\n",
    "        X_feat_train = X_feat_test = None\n",
    "        feature_pipeline = AdvancedTextPreprocessor()\n",
    "\n",
    "        print(\"\\n‚úÖ Basic data preparation completed successfully!\")\n",
    "        ADVANCED_FEATURES = False\n",
    "\n",
    "    except Exception as e2:\n",
    "        print(f\"\\n‚ùå Both advanced and basic preparation failed:\\n   ‚Ü≥ {e2}\")\n",
    "        print(\"‚ö†Ô∏è  Please inspect your dataset and preprocessing pipeline.\")\n",
    "        raise e2\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Summary of the preparation results\n",
    "# -----------------------------------------------------------------\n",
    "print(\"\\nüìä DATA PREPARATION SUMMARY\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Training samples:       {len(X_text_train):,}\")\n",
    "print(f\"Testing samples:        {len(X_text_test):,}\")\n",
    "print(f\"Advanced features used: {ADVANCED_FEATURES}\")\n",
    "\n",
    "if ADVANCED_FEATURES and X_feat_train is not None:\n",
    "    print(f\"Linguistic feature dims: {X_feat_train.shape[1]}\")\n",
    "\n",
    "print(f\"Label encoder applied:  {'Yes' if label_encoder else 'No'}\")\n",
    "print(\"-\" * 60)\n",
    "print(\"‚úÖ Data successfully prepared and ready for vectorization & model training!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6256eb3-a6e8-4dc4-b7cb-60c87e067072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üî• STARTING COMPREHENSIVE EVALUATION WITH NOVEL APPROACHES\n",
      "======================================================================\n",
      "\n",
      "üöÄ Starting comprehensive model evaluation...\n",
      "üì¶ Standard models: 27\n",
      "üß© Custom models:   3\n",
      "\n",
      "üìù Using vectorizer: tfidf_unigram\n",
      "\n",
      "[1/408] üîÑ Evaluating LogisticRegression + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[2/408] üîÑ Evaluating LogisticRegression_L1 + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[3/408] üîÑ Evaluating RidgeClassifier + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[4/408] üîÑ Evaluating SGDClassifier + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[5/408] üîÑ Evaluating MultinomialNB + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[6/408] üîÑ Evaluating ComplementNB + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[7/408] üîÑ Evaluating BernoulliNB + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[8/408] üîÑ Evaluating RandomForest + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[9/408] üîÑ Evaluating ExtraTrees + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[10/408] üîÑ Evaluating GradientBoosting + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[11/408] üîÑ Evaluating LinearSVC + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[12/408] üîÑ Evaluating MLPClassifier + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[13/408] üîÑ Evaluating KNN + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[14/408] üîÑ Evaluating XGBoost + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[15/408] üîÑ Evaluating LightGBM + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[16/408] üîÑ Evaluating CatBoost + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[17/408] üîÑ Evaluating linear_stacking_voting + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[18/408] üîÑ Evaluating ada_boost_tree + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[19/408] üîÑ Evaluating ada_boost_simple + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[20/408] üîÑ Evaluating bagging_lr + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[21/408] üîÑ Evaluating bagging_sgd + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[22/408] üîÑ Evaluating feature_selection_lr + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[23/408] üîÑ Evaluating feature_selection_rf + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[24/408] üîÑ Evaluating calibrated_rf + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[25/408] üîÑ Evaluating calibrated_svm + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[26/408] üîÑ Evaluating xgb_custom + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[27/408] üîÑ Evaluating lgbm_custom + tfidf_unigram ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: tfidf_bigram\n",
      "\n",
      "[28/408] üîÑ Evaluating LogisticRegression + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[29/408] üîÑ Evaluating LogisticRegression_L1 + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[30/408] üîÑ Evaluating RidgeClassifier + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[31/408] üîÑ Evaluating SGDClassifier + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[32/408] üîÑ Evaluating MultinomialNB + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[33/408] üîÑ Evaluating ComplementNB + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[34/408] üîÑ Evaluating BernoulliNB + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[35/408] üîÑ Evaluating RandomForest + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[36/408] üîÑ Evaluating ExtraTrees + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[37/408] üîÑ Evaluating GradientBoosting + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[38/408] üîÑ Evaluating LinearSVC + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[39/408] üîÑ Evaluating MLPClassifier + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[40/408] üîÑ Evaluating KNN + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[41/408] üîÑ Evaluating XGBoost + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[42/408] üîÑ Evaluating LightGBM + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[43/408] üîÑ Evaluating CatBoost + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[44/408] üîÑ Evaluating linear_stacking_voting + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[45/408] üîÑ Evaluating ada_boost_tree + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[46/408] üîÑ Evaluating ada_boost_simple + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[47/408] üîÑ Evaluating bagging_lr + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[48/408] üîÑ Evaluating bagging_sgd + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[49/408] üîÑ Evaluating feature_selection_lr + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[50/408] üîÑ Evaluating feature_selection_rf + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[51/408] üîÑ Evaluating calibrated_rf + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[52/408] üîÑ Evaluating calibrated_svm + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[53/408] üîÑ Evaluating xgb_custom + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[54/408] üîÑ Evaluating lgbm_custom + tfidf_bigram ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: tfidf_trigram\n",
      "\n",
      "[55/408] üîÑ Evaluating LogisticRegression + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[56/408] üîÑ Evaluating LogisticRegression_L1 + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[57/408] üîÑ Evaluating RidgeClassifier + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[58/408] üîÑ Evaluating SGDClassifier + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[59/408] üîÑ Evaluating MultinomialNB + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[60/408] üîÑ Evaluating ComplementNB + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[61/408] üîÑ Evaluating BernoulliNB + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[62/408] üîÑ Evaluating RandomForest + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[63/408] üîÑ Evaluating ExtraTrees + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[64/408] üîÑ Evaluating GradientBoosting + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[65/408] üîÑ Evaluating LinearSVC + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[66/408] üîÑ Evaluating MLPClassifier + tfidf_trigram ...\n",
      "   ‚è≠Ô∏è Skipping heavy combination: MLPClassifier with tfidf_trigram\n",
      "\n",
      "[67/408] üîÑ Evaluating KNN + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[68/408] üîÑ Evaluating XGBoost + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[69/408] üîÑ Evaluating LightGBM + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[70/408] üîÑ Evaluating CatBoost + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[71/408] üîÑ Evaluating linear_stacking_voting + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[72/408] üîÑ Evaluating ada_boost_tree + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[73/408] üîÑ Evaluating ada_boost_simple + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[74/408] üîÑ Evaluating bagging_lr + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[75/408] üîÑ Evaluating bagging_sgd + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[76/408] üîÑ Evaluating feature_selection_lr + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[77/408] üîÑ Evaluating feature_selection_rf + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[78/408] üîÑ Evaluating calibrated_rf + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[79/408] üîÑ Evaluating calibrated_svm + tfidf_trigram ...\n",
      "   ‚è≠Ô∏è Skipping heavy combination: calibrated_svm with tfidf_trigram\n",
      "\n",
      "[80/408] üîÑ Evaluating xgb_custom + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[81/408] üîÑ Evaluating lgbm_custom + tfidf_trigram ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: count_unigram\n",
      "\n",
      "[82/408] üîÑ Evaluating LogisticRegression + count_unigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[83/408] üîÑ Evaluating LogisticRegression_L1 + count_unigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[84/408] üîÑ Evaluating RidgeClassifier + count_unigram ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[85/408] üîÑ Evaluating SGDClassifier + count_unigram ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[86/408] üîÑ Evaluating MultinomialNB + count_unigram ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[87/408] üîÑ Evaluating ComplementNB + count_unigram ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[88/408] üîÑ Evaluating BernoulliNB + count_unigram ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[89/408] üîÑ Evaluating RandomForest + count_unigram ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[90/408] üîÑ Evaluating ExtraTrees + count_unigram ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[91/408] üîÑ Evaluating GradientBoosting + count_unigram ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[92/408] üîÑ Evaluating LinearSVC + count_unigram ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[93/408] üîÑ Evaluating MLPClassifier + count_unigram ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[94/408] üîÑ Evaluating KNN + count_unigram ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[95/408] üîÑ Evaluating XGBoost + count_unigram ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[96/408] üîÑ Evaluating LightGBM + count_unigram ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[97/408] üîÑ Evaluating CatBoost + count_unigram ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[98/408] üîÑ Evaluating linear_stacking_voting + count_unigram ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[99/408] üîÑ Evaluating ada_boost_tree + count_unigram ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[100/408] üîÑ Evaluating ada_boost_simple + count_unigram ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[101/408] üîÑ Evaluating bagging_lr + count_unigram ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[102/408] üîÑ Evaluating bagging_sgd + count_unigram ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[103/408] üîÑ Evaluating feature_selection_lr + count_unigram ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[104/408] üîÑ Evaluating feature_selection_rf + count_unigram ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[105/408] üîÑ Evaluating calibrated_rf + count_unigram ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[106/408] üîÑ Evaluating calibrated_svm + count_unigram ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[107/408] üîÑ Evaluating xgb_custom + count_unigram ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[108/408] üîÑ Evaluating lgbm_custom + count_unigram ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: count_bigram\n",
      "\n",
      "[109/408] üîÑ Evaluating LogisticRegression + count_bigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[110/408] üîÑ Evaluating LogisticRegression_L1 + count_bigram ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[111/408] üîÑ Evaluating RidgeClassifier + count_bigram ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[112/408] üîÑ Evaluating SGDClassifier + count_bigram ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[113/408] üîÑ Evaluating MultinomialNB + count_bigram ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[114/408] üîÑ Evaluating ComplementNB + count_bigram ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[115/408] üîÑ Evaluating BernoulliNB + count_bigram ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[116/408] üîÑ Evaluating RandomForest + count_bigram ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[117/408] üîÑ Evaluating ExtraTrees + count_bigram ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[118/408] üîÑ Evaluating GradientBoosting + count_bigram ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[119/408] üîÑ Evaluating LinearSVC + count_bigram ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[120/408] üîÑ Evaluating MLPClassifier + count_bigram ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[121/408] üîÑ Evaluating KNN + count_bigram ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[122/408] üîÑ Evaluating XGBoost + count_bigram ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[123/408] üîÑ Evaluating LightGBM + count_bigram ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[124/408] üîÑ Evaluating CatBoost + count_bigram ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[125/408] üîÑ Evaluating linear_stacking_voting + count_bigram ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[126/408] üîÑ Evaluating ada_boost_tree + count_bigram ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[127/408] üîÑ Evaluating ada_boost_simple + count_bigram ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[128/408] üîÑ Evaluating bagging_lr + count_bigram ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[129/408] üîÑ Evaluating bagging_sgd + count_bigram ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[130/408] üîÑ Evaluating feature_selection_lr + count_bigram ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[131/408] üîÑ Evaluating feature_selection_rf + count_bigram ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[132/408] üîÑ Evaluating calibrated_rf + count_bigram ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[133/408] üîÑ Evaluating calibrated_svm + count_bigram ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[134/408] üîÑ Evaluating xgb_custom + count_bigram ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[135/408] üîÑ Evaluating lgbm_custom + count_bigram ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: tfidf_char\n",
      "\n",
      "[136/408] üîÑ Evaluating LogisticRegression + tfidf_char ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[137/408] üîÑ Evaluating LogisticRegression_L1 + tfidf_char ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[138/408] üîÑ Evaluating RidgeClassifier + tfidf_char ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[139/408] üîÑ Evaluating SGDClassifier + tfidf_char ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[140/408] üîÑ Evaluating MultinomialNB + tfidf_char ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[141/408] üîÑ Evaluating ComplementNB + tfidf_char ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[142/408] üîÑ Evaluating BernoulliNB + tfidf_char ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[143/408] üîÑ Evaluating RandomForest + tfidf_char ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[144/408] üîÑ Evaluating ExtraTrees + tfidf_char ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[145/408] üîÑ Evaluating GradientBoosting + tfidf_char ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[146/408] üîÑ Evaluating LinearSVC + tfidf_char ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[147/408] üîÑ Evaluating MLPClassifier + tfidf_char ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[148/408] üîÑ Evaluating KNN + tfidf_char ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[149/408] üîÑ Evaluating XGBoost + tfidf_char ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[150/408] üîÑ Evaluating LightGBM + tfidf_char ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[151/408] üîÑ Evaluating CatBoost + tfidf_char ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[152/408] üîÑ Evaluating linear_stacking_voting + tfidf_char ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[153/408] üîÑ Evaluating ada_boost_tree + tfidf_char ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[154/408] üîÑ Evaluating ada_boost_simple + tfidf_char ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[155/408] üîÑ Evaluating bagging_lr + tfidf_char ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[156/408] üîÑ Evaluating bagging_sgd + tfidf_char ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[157/408] üîÑ Evaluating feature_selection_lr + tfidf_char ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[158/408] üîÑ Evaluating feature_selection_rf + tfidf_char ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[159/408] üîÑ Evaluating calibrated_rf + tfidf_char ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[160/408] üîÑ Evaluating calibrated_svm + tfidf_char ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[161/408] üîÑ Evaluating xgb_custom + tfidf_char ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[162/408] üîÑ Evaluating lgbm_custom + tfidf_char ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: bow_binary\n",
      "\n",
      "[163/408] üîÑ Evaluating LogisticRegression + bow_binary ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[164/408] üîÑ Evaluating LogisticRegression_L1 + bow_binary ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[165/408] üîÑ Evaluating RidgeClassifier + bow_binary ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[166/408] üîÑ Evaluating SGDClassifier + bow_binary ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[167/408] üîÑ Evaluating MultinomialNB + bow_binary ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[168/408] üîÑ Evaluating ComplementNB + bow_binary ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[169/408] üîÑ Evaluating BernoulliNB + bow_binary ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[170/408] üîÑ Evaluating RandomForest + bow_binary ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[171/408] üîÑ Evaluating ExtraTrees + bow_binary ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[172/408] üîÑ Evaluating GradientBoosting + bow_binary ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[173/408] üîÑ Evaluating LinearSVC + bow_binary ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[174/408] üîÑ Evaluating MLPClassifier + bow_binary ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[175/408] üîÑ Evaluating KNN + bow_binary ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[176/408] üîÑ Evaluating XGBoost + bow_binary ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[177/408] üîÑ Evaluating LightGBM + bow_binary ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[178/408] üîÑ Evaluating CatBoost + bow_binary ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[179/408] üîÑ Evaluating linear_stacking_voting + bow_binary ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[180/408] üîÑ Evaluating ada_boost_tree + bow_binary ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[181/408] üîÑ Evaluating ada_boost_simple + bow_binary ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[182/408] üîÑ Evaluating bagging_lr + bow_binary ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[183/408] üîÑ Evaluating bagging_sgd + bow_binary ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[184/408] üîÑ Evaluating feature_selection_lr + bow_binary ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[185/408] üîÑ Evaluating feature_selection_rf + bow_binary ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[186/408] üîÑ Evaluating calibrated_rf + bow_binary ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[187/408] üîÑ Evaluating calibrated_svm + bow_binary ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[188/408] üîÑ Evaluating xgb_custom + bow_binary ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[189/408] üîÑ Evaluating lgbm_custom + bow_binary ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: bow_freq\n",
      "\n",
      "[190/408] üîÑ Evaluating LogisticRegression + bow_freq ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[191/408] üîÑ Evaluating LogisticRegression_L1 + bow_freq ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[192/408] üîÑ Evaluating RidgeClassifier + bow_freq ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[193/408] üîÑ Evaluating SGDClassifier + bow_freq ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[194/408] üîÑ Evaluating MultinomialNB + bow_freq ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[195/408] üîÑ Evaluating ComplementNB + bow_freq ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[196/408] üîÑ Evaluating BernoulliNB + bow_freq ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[197/408] üîÑ Evaluating RandomForest + bow_freq ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[198/408] üîÑ Evaluating ExtraTrees + bow_freq ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[199/408] üîÑ Evaluating GradientBoosting + bow_freq ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[200/408] üîÑ Evaluating LinearSVC + bow_freq ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[201/408] üîÑ Evaluating MLPClassifier + bow_freq ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[202/408] üîÑ Evaluating KNN + bow_freq ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[203/408] üîÑ Evaluating XGBoost + bow_freq ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[204/408] üîÑ Evaluating LightGBM + bow_freq ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[205/408] üîÑ Evaluating CatBoost + bow_freq ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[206/408] üîÑ Evaluating linear_stacking_voting + bow_freq ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[207/408] üîÑ Evaluating ada_boost_tree + bow_freq ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[208/408] üîÑ Evaluating ada_boost_simple + bow_freq ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[209/408] üîÑ Evaluating bagging_lr + bow_freq ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[210/408] üîÑ Evaluating bagging_sgd + bow_freq ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[211/408] üîÑ Evaluating feature_selection_lr + bow_freq ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[212/408] üîÑ Evaluating feature_selection_rf + bow_freq ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[213/408] üîÑ Evaluating calibrated_rf + bow_freq ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[214/408] üîÑ Evaluating calibrated_svm + bow_freq ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[215/408] üîÑ Evaluating xgb_custom + bow_freq ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[216/408] üîÑ Evaluating lgbm_custom + bow_freq ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: tfidf_sublinear\n",
      "\n",
      "[217/408] üîÑ Evaluating LogisticRegression + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[218/408] üîÑ Evaluating LogisticRegression_L1 + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[219/408] üîÑ Evaluating RidgeClassifier + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[220/408] üîÑ Evaluating SGDClassifier + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[221/408] üîÑ Evaluating MultinomialNB + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[222/408] üîÑ Evaluating ComplementNB + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[223/408] üîÑ Evaluating BernoulliNB + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[224/408] üîÑ Evaluating RandomForest + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[225/408] üîÑ Evaluating ExtraTrees + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[226/408] üîÑ Evaluating GradientBoosting + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[227/408] üîÑ Evaluating LinearSVC + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[228/408] üîÑ Evaluating MLPClassifier + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[229/408] üîÑ Evaluating KNN + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[230/408] üîÑ Evaluating XGBoost + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[231/408] üîÑ Evaluating LightGBM + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[232/408] üîÑ Evaluating CatBoost + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[233/408] üîÑ Evaluating linear_stacking_voting + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[234/408] üîÑ Evaluating ada_boost_tree + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[235/408] üîÑ Evaluating ada_boost_simple + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[236/408] üîÑ Evaluating bagging_lr + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[237/408] üîÑ Evaluating bagging_sgd + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[238/408] üîÑ Evaluating feature_selection_lr + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[239/408] üîÑ Evaluating feature_selection_rf + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[240/408] üîÑ Evaluating calibrated_rf + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[241/408] üîÑ Evaluating calibrated_svm + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[242/408] üîÑ Evaluating xgb_custom + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[243/408] üîÑ Evaluating lgbm_custom + tfidf_sublinear ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: hybrid_char_word\n",
      "\n",
      "[244/408] üîÑ Evaluating LogisticRegression + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[245/408] üîÑ Evaluating LogisticRegression_L1 + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[246/408] üîÑ Evaluating RidgeClassifier + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[247/408] üîÑ Evaluating SGDClassifier + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[248/408] üîÑ Evaluating MultinomialNB + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[249/408] üîÑ Evaluating ComplementNB + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[250/408] üîÑ Evaluating BernoulliNB + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[251/408] üîÑ Evaluating RandomForest + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[252/408] üîÑ Evaluating ExtraTrees + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[253/408] üîÑ Evaluating GradientBoosting + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[254/408] üîÑ Evaluating LinearSVC + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[255/408] üîÑ Evaluating MLPClassifier + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[256/408] üîÑ Evaluating KNN + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[257/408] üîÑ Evaluating XGBoost + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[258/408] üîÑ Evaluating LightGBM + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[259/408] üîÑ Evaluating CatBoost + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[260/408] üîÑ Evaluating linear_stacking_voting + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[261/408] üîÑ Evaluating ada_boost_tree + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[262/408] üîÑ Evaluating ada_boost_simple + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[263/408] üîÑ Evaluating bagging_lr + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[264/408] üîÑ Evaluating bagging_sgd + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[265/408] üîÑ Evaluating feature_selection_lr + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[266/408] üîÑ Evaluating feature_selection_rf + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[267/408] üîÑ Evaluating calibrated_rf + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[268/408] üîÑ Evaluating calibrated_svm + hybrid_char_word ...\n",
      "   ‚è≠Ô∏è Skipping heavy combination: calibrated_svm with hybrid_char_word\n",
      "\n",
      "[269/408] üîÑ Evaluating xgb_custom + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[270/408] üîÑ Evaluating lgbm_custom + hybrid_char_word ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: mental_health_focused\n",
      "\n",
      "[271/408] üîÑ Evaluating LogisticRegression + mental_health_focused ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[272/408] üîÑ Evaluating LogisticRegression_L1 + mental_health_focused ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[273/408] üîÑ Evaluating RidgeClassifier + mental_health_focused ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[274/408] üîÑ Evaluating SGDClassifier + mental_health_focused ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[275/408] üîÑ Evaluating MultinomialNB + mental_health_focused ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[276/408] üîÑ Evaluating ComplementNB + mental_health_focused ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[277/408] üîÑ Evaluating BernoulliNB + mental_health_focused ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[278/408] üîÑ Evaluating RandomForest + mental_health_focused ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[279/408] üîÑ Evaluating ExtraTrees + mental_health_focused ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[280/408] üîÑ Evaluating GradientBoosting + mental_health_focused ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[281/408] üîÑ Evaluating LinearSVC + mental_health_focused ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[282/408] üîÑ Evaluating MLPClassifier + mental_health_focused ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[283/408] üîÑ Evaluating KNN + mental_health_focused ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[284/408] üîÑ Evaluating XGBoost + mental_health_focused ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[285/408] üîÑ Evaluating LightGBM + mental_health_focused ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[286/408] üîÑ Evaluating CatBoost + mental_health_focused ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[287/408] üîÑ Evaluating linear_stacking_voting + mental_health_focused ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[288/408] üîÑ Evaluating ada_boost_tree + mental_health_focused ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[289/408] üîÑ Evaluating ada_boost_simple + mental_health_focused ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[290/408] üîÑ Evaluating bagging_lr + mental_health_focused ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[291/408] üîÑ Evaluating bagging_sgd + mental_health_focused ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[292/408] üîÑ Evaluating feature_selection_lr + mental_health_focused ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[293/408] üîÑ Evaluating feature_selection_rf + mental_health_focused ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[294/408] üîÑ Evaluating calibrated_rf + mental_health_focused ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[295/408] üîÑ Evaluating calibrated_svm + mental_health_focused ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[296/408] üîÑ Evaluating xgb_custom + mental_health_focused ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[297/408] üîÑ Evaluating lgbm_custom + mental_health_focused ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: weighted_tfidf\n",
      "\n",
      "[298/408] üîÑ Evaluating LogisticRegression + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[299/408] üîÑ Evaluating LogisticRegression_L1 + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[300/408] üîÑ Evaluating RidgeClassifier + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[301/408] üîÑ Evaluating SGDClassifier + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[302/408] üîÑ Evaluating MultinomialNB + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[303/408] üîÑ Evaluating ComplementNB + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[304/408] üîÑ Evaluating BernoulliNB + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[305/408] üîÑ Evaluating RandomForest + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[306/408] üîÑ Evaluating ExtraTrees + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[307/408] üîÑ Evaluating GradientBoosting + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[308/408] üîÑ Evaluating LinearSVC + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[309/408] üîÑ Evaluating MLPClassifier + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[310/408] üîÑ Evaluating KNN + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[311/408] üîÑ Evaluating XGBoost + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[312/408] üîÑ Evaluating LightGBM + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[313/408] üîÑ Evaluating CatBoost + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[314/408] üîÑ Evaluating linear_stacking_voting + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[315/408] üîÑ Evaluating ada_boost_tree + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[316/408] üîÑ Evaluating ada_boost_simple + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[317/408] üîÑ Evaluating bagging_lr + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[318/408] üîÑ Evaluating bagging_sgd + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[319/408] üîÑ Evaluating feature_selection_lr + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[320/408] üîÑ Evaluating feature_selection_rf + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[321/408] üîÑ Evaluating calibrated_rf + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[322/408] üîÑ Evaluating calibrated_svm + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating calibrated_svm: name 'evaluate_model' is not defined\n",
      "\n",
      "[323/408] üîÑ Evaluating xgb_custom + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[324/408] üîÑ Evaluating lgbm_custom + weighted_tfidf ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: custom_stress\n",
      "\n",
      "[325/408] üîÑ Evaluating LogisticRegression + custom_stress ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[326/408] üîÑ Evaluating LogisticRegression_L1 + custom_stress ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[327/408] üîÑ Evaluating RidgeClassifier + custom_stress ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[328/408] üîÑ Evaluating SGDClassifier + custom_stress ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[329/408] üîÑ Evaluating MultinomialNB + custom_stress ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[330/408] üîÑ Evaluating ComplementNB + custom_stress ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[331/408] üîÑ Evaluating BernoulliNB + custom_stress ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[332/408] üîÑ Evaluating RandomForest + custom_stress ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[333/408] üîÑ Evaluating ExtraTrees + custom_stress ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[334/408] üîÑ Evaluating GradientBoosting + custom_stress ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[335/408] üîÑ Evaluating LinearSVC + custom_stress ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[336/408] üîÑ Evaluating MLPClassifier + custom_stress ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[337/408] üîÑ Evaluating KNN + custom_stress ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[338/408] üîÑ Evaluating XGBoost + custom_stress ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[339/408] üîÑ Evaluating LightGBM + custom_stress ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[340/408] üîÑ Evaluating CatBoost + custom_stress ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[341/408] üîÑ Evaluating linear_stacking_voting + custom_stress ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[342/408] üîÑ Evaluating ada_boost_tree + custom_stress ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[343/408] üîÑ Evaluating ada_boost_simple + custom_stress ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[344/408] üîÑ Evaluating bagging_lr + custom_stress ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[345/408] üîÑ Evaluating bagging_sgd + custom_stress ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[346/408] üîÑ Evaluating feature_selection_lr + custom_stress ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[347/408] üîÑ Evaluating feature_selection_rf + custom_stress ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[348/408] üîÑ Evaluating calibrated_rf + custom_stress ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[349/408] üîÑ Evaluating calibrated_svm + custom_stress ...\n",
      "   ‚è≠Ô∏è Skipping heavy combination: calibrated_svm with custom_stress\n",
      "\n",
      "[350/408] üîÑ Evaluating xgb_custom + custom_stress ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[351/408] üîÑ Evaluating lgbm_custom + custom_stress ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: ensemble_tfidf\n",
      "\n",
      "[352/408] üîÑ Evaluating LogisticRegression + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[353/408] üîÑ Evaluating LogisticRegression_L1 + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[354/408] üîÑ Evaluating RidgeClassifier + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[355/408] üîÑ Evaluating SGDClassifier + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[356/408] üîÑ Evaluating MultinomialNB + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[357/408] üîÑ Evaluating ComplementNB + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[358/408] üîÑ Evaluating BernoulliNB + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[359/408] üîÑ Evaluating RandomForest + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[360/408] üîÑ Evaluating ExtraTrees + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[361/408] üîÑ Evaluating GradientBoosting + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[362/408] üîÑ Evaluating LinearSVC + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[363/408] üîÑ Evaluating MLPClassifier + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[364/408] üîÑ Evaluating KNN + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[365/408] üîÑ Evaluating XGBoost + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[366/408] üîÑ Evaluating LightGBM + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[367/408] üîÑ Evaluating CatBoost + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[368/408] üîÑ Evaluating linear_stacking_voting + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[369/408] üîÑ Evaluating ada_boost_tree + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[370/408] üîÑ Evaluating ada_boost_simple + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[371/408] üîÑ Evaluating bagging_lr + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[372/408] üîÑ Evaluating bagging_sgd + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[373/408] üîÑ Evaluating feature_selection_lr + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[374/408] üîÑ Evaluating feature_selection_rf + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[375/408] üîÑ Evaluating calibrated_rf + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[376/408] üîÑ Evaluating calibrated_svm + ensemble_tfidf ...\n",
      "   ‚è≠Ô∏è Skipping heavy combination: calibrated_svm with ensemble_tfidf\n",
      "\n",
      "[377/408] üîÑ Evaluating xgb_custom + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[378/408] üîÑ Evaluating lgbm_custom + ensemble_tfidf ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üìù Using vectorizer: count_tfidf_ensemble\n",
      "\n",
      "[379/408] üîÑ Evaluating LogisticRegression + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating LogisticRegression: name 'evaluate_model' is not defined\n",
      "\n",
      "[380/408] üîÑ Evaluating LogisticRegression_L1 + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating LogisticRegression_L1: name 'evaluate_model' is not defined\n",
      "\n",
      "[381/408] üîÑ Evaluating RidgeClassifier + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating RidgeClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[382/408] üîÑ Evaluating SGDClassifier + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating SGDClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[383/408] üîÑ Evaluating MultinomialNB + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating MultinomialNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[384/408] üîÑ Evaluating ComplementNB + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating ComplementNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[385/408] üîÑ Evaluating BernoulliNB + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating BernoulliNB: name 'evaluate_model' is not defined\n",
      "\n",
      "[386/408] üîÑ Evaluating RandomForest + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating RandomForest: name 'evaluate_model' is not defined\n",
      "\n",
      "[387/408] üîÑ Evaluating ExtraTrees + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating ExtraTrees: name 'evaluate_model' is not defined\n",
      "\n",
      "[388/408] üîÑ Evaluating GradientBoosting + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating GradientBoosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[389/408] üîÑ Evaluating LinearSVC + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating LinearSVC: name 'evaluate_model' is not defined\n",
      "\n",
      "[390/408] üîÑ Evaluating MLPClassifier + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating MLPClassifier: name 'evaluate_model' is not defined\n",
      "\n",
      "[391/408] üîÑ Evaluating KNN + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating KNN: name 'evaluate_model' is not defined\n",
      "\n",
      "[392/408] üîÑ Evaluating XGBoost + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating XGBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[393/408] üîÑ Evaluating LightGBM + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating LightGBM: name 'evaluate_model' is not defined\n",
      "\n",
      "[394/408] üîÑ Evaluating CatBoost + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating CatBoost: name 'evaluate_model' is not defined\n",
      "\n",
      "[395/408] üîÑ Evaluating linear_stacking_voting + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating linear_stacking_voting: name 'evaluate_model' is not defined\n",
      "\n",
      "[396/408] üîÑ Evaluating ada_boost_tree + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating ada_boost_tree: name 'evaluate_model' is not defined\n",
      "\n",
      "[397/408] üîÑ Evaluating ada_boost_simple + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating ada_boost_simple: name 'evaluate_model' is not defined\n",
      "\n",
      "[398/408] üîÑ Evaluating bagging_lr + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating bagging_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[399/408] üîÑ Evaluating bagging_sgd + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating bagging_sgd: name 'evaluate_model' is not defined\n",
      "\n",
      "[400/408] üîÑ Evaluating feature_selection_lr + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating feature_selection_lr: name 'evaluate_model' is not defined\n",
      "\n",
      "[401/408] üîÑ Evaluating feature_selection_rf + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating feature_selection_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[402/408] üîÑ Evaluating calibrated_rf + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating calibrated_rf: name 'evaluate_model' is not defined\n",
      "\n",
      "[403/408] üîÑ Evaluating calibrated_svm + count_tfidf_ensemble ...\n",
      "   ‚è≠Ô∏è Skipping heavy combination: calibrated_svm with count_tfidf_ensemble\n",
      "\n",
      "[404/408] üîÑ Evaluating xgb_custom + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating xgb_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "[405/408] üîÑ Evaluating lgbm_custom + count_tfidf_ensemble ...\n",
      "   ‚ùå Error evaluating lgbm_custom: name 'evaluate_model' is not defined\n",
      "\n",
      "üéØ Evaluating custom ensemble models...\n",
      "\n",
      "[406/408] üîÑ Evaluating deep_feature_ensemble (custom)...\n",
      "   ‚ùå Error evaluating deep_feature_ensemble: name 'evaluate_model' is not defined\n",
      "\n",
      "[407/408] üîÑ Evaluating adaptive_boosting (custom)...\n",
      "   ‚ùå Error evaluating adaptive_boosting: name 'evaluate_model' is not defined\n",
      "\n",
      "[408/408] üîÑ Evaluating stress_focused_ensemble (custom)...\n",
      "   ‚ùå Error evaluating stress_focused_ensemble: name 'evaluate_model' is not defined\n",
      "\n",
      "üèÅ Comprehensive evaluation complete in 0.0 minutes!\n",
      "‚úÖ Successfully evaluated 0 model‚Äìvectorizer combinations.\n",
      "\n",
      "\n",
      "‚úÖ Evaluation finished!\n",
      "üßÆ Total combinations tested: 0\n",
      "üß† Novel methods included: BoW, TF-IDF, Deep Ensemble, Stress-Focused Models, etc.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üî• CELL 9 ‚Äî COMPREHENSIVE MODEL EVALUATION LOOP\n",
    "# ==========================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def run_comprehensive_evaluation():\n",
    "    \"\"\"Run full evaluation of all vectorizers and models (standard + custom).\"\"\"\n",
    "    \n",
    "    print(\"\\nüöÄ Starting comprehensive model evaluation...\")\n",
    "    start_global = time.time()\n",
    "\n",
    "    all_results = []\n",
    "    standard_models = {}\n",
    "    custom_models = {}\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Separate standard and custom (novel/ensemble) models\n",
    "    # ------------------------------------------------------------\n",
    "    for name, model in models.items():\n",
    "        if any(x in name.lower() for x in [\n",
    "            'deep_feature_ensemble', 'stress_focused_ensemble', 'adaptive_boosting'\n",
    "        ]):\n",
    "            custom_models[name] = model\n",
    "        else:\n",
    "            standard_models[name] = model\n",
    "\n",
    "    print(f\"üì¶ Standard models: {len(standard_models)}\")\n",
    "    print(f\"üß© Custom models:   {len(custom_models)}\")\n",
    "\n",
    "    total_combinations = len(vectorizers) * len(standard_models) + len(custom_models)\n",
    "    current = 0\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Evaluate Standard Models with Vectorizers\n",
    "    # ------------------------------------------------------------\n",
    "    for vec_name, vectorizer in vectorizers.items():\n",
    "        print(f\"\\nüìù Using vectorizer: {vec_name}\")\n",
    "\n",
    "        skip_vectorizer = any(\n",
    "            x in vec_name.lower() for x in [\"custom_stress\", \"hybrid_char_word\", \"ensemble\"]\n",
    "        )\n",
    "\n",
    "        for model_name, model in standard_models.items():\n",
    "            current += 1\n",
    "            print(f\"\\n[{current}/{total_combinations}] üîÑ Evaluating {model_name} + {vec_name} ...\")\n",
    "\n",
    "            # Skip heavy combinations for efficiency\n",
    "            skip_conditions = [\n",
    "                (skip_vectorizer and 'svm' in model_name.lower()),\n",
    "                ('svm' in model_name.lower() and 'trigram' in vec_name),\n",
    "                ('mlpclassifier' in model_name.lower() and 'trigram' in vec_name),\n",
    "                ('ensemble' in vec_name.lower() and 'ensemble' in model_name.lower()),\n",
    "            ]\n",
    "            if any(skip_conditions):\n",
    "                print(f\"   ‚è≠Ô∏è Skipping heavy combination: {model_name} with {vec_name}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                results = evaluate_model(\n",
    "                    model=model,\n",
    "                    model_name=model_name,\n",
    "                    X_text_train=X_text_train,\n",
    "                    X_text_test=X_text_test,\n",
    "                    X_feat_train=X_feat_train,\n",
    "                    X_feat_test=X_feat_test,\n",
    "                    y_train=y_train,\n",
    "                    y_test=y_test,\n",
    "                    vectorizer=vectorizer,\n",
    "                )\n",
    "\n",
    "                if results:\n",
    "                    all_results.append(results)\n",
    "                    print(\n",
    "                        f\"   ‚úÖ {model_name} done ‚Äî \"\n",
    "                        f\"Acc={results['test_accuracy']:.3f}, \"\n",
    "                        f\"F1={results['test_f1']:.3f}, \"\n",
    "                        f\"MCC={results['test_mcc']:.3f}, \"\n",
    "                        f\"Time={results['training_time_sec']:.2f}s\"\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error evaluating {model_name}: {str(e)[:80]}\")\n",
    "                continue\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Evaluate Custom Models (Deep Ensembles, Stress-Focused, etc.)\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\nüéØ Evaluating custom ensemble models...\")\n",
    "    default_vectorizer = TfidfVectorizer(\n",
    "        max_features=10000, ngram_range=(1, 1), min_df=3, max_df=0.95, stop_words=\"english\"\n",
    "    )\n",
    "\n",
    "    for model_name, model in custom_models.items():\n",
    "        current += 1\n",
    "        print(f\"\\n[{current}/{total_combinations}] üîÑ Evaluating {model_name} (custom)...\")\n",
    "\n",
    "        try:\n",
    "            results = evaluate_model(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                X_text_train=X_text_train,\n",
    "                X_text_test=X_text_test,\n",
    "                X_feat_train=X_feat_train,\n",
    "                X_feat_test=X_feat_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test,\n",
    "                vectorizer=default_vectorizer,\n",
    "            )\n",
    "\n",
    "            if results:\n",
    "                all_results.append(results)\n",
    "                print(\n",
    "                    f\"   ‚úÖ {model_name} done ‚Äî \"\n",
    "                    f\"Acc={results['test_accuracy']:.3f}, \"\n",
    "                    f\"F1={results['test_f1']:.3f}, \"\n",
    "                    f\"MCC={results['test_mcc']:.3f}, \"\n",
    "                    f\"Time={results['training_time_sec']:.2f}s\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error evaluating {model_name}: {str(e)[:80]}\")\n",
    "            continue\n",
    "\n",
    "    elapsed = time.time() - start_global\n",
    "    print(f\"\\nüèÅ Comprehensive evaluation complete in {elapsed/60:.1f} minutes!\")\n",
    "    print(f\"‚úÖ Successfully evaluated {len(all_results)} model‚Äìvectorizer combinations.\\n\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run the Comprehensive Evaluation\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üî• STARTING COMPREHENSIVE EVALUATION WITH NOVEL APPROACHES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "evaluation_results = run_comprehensive_evaluation()\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation finished!\")\n",
    "print(f\"üßÆ Total combinations tested: {len(evaluation_results)}\")\n",
    "print(\"üß† Novel methods included: BoW, TF-IDF, Deep Ensemble, Stress-Focused Models, etc.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfda13-faf9-4d73-8044-37ce95d47cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
